<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>3</epicId>
    <storyId>12</storyId>
    <title>Production Handoff & Documentation</title>
    <status>drafted</status>
    <generatedAt>2025-11-24</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>/home/ethr/01-projects/ai-experiments/i-o/bmad-docs/stories/3-12-production-handoff-documentation.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>Als ethr,</asA>
    <iWant>möchte ich vollständige Dokumentation für System-Betrieb und Maintenance haben,</iWant>
    <soThat>sodass ich das System langfristig selbstständig betreiben kann.</soThat>
    <tasks>### Task 1: Create README.md - Project Overview (AC: 3.12.1)

- [ ] Subtask 1.1: Erstelle `/docs/README.md` mit System-Architektur Section
  - High-Level ASCII Diagram (aus architecture.md übernehmen/vereinfachen)
  - Komponenten-Liste (7 Tools, 5 Resources)
  - Datenfluss-Beschreibung
- [ ] Subtask 1.2: Ergänze Key Features Section
  - L0/L2 Memory, Hybrid Search, CoT, Reflexion, Drift Detection, Budget Monitoring
  - Kurze 1-2 Sätze pro Feature
- [ ] Subtask 1.3: Ergänze Budget & Performance Metrics
  - Cost Breakdown (€5-10/mo → €2-3/mo)
  - Latency Targets (<5s p95)
  - Precision@5 Target (>0.75)
- [ ] Subtask 1.4: Ergänze Quick Start Section
  - Links zu anderen Docs
  - Minimum Requirements Summary

### Task 2: Create Installation Guide (AC: 3.12.2)

- [ ] Subtask 2.1: Erstelle `/docs/installation-guide.md` mit Prerequisites
  - System Requirements (Arch Linux, Python 3.11+, PostgreSQL 15+)
  - External Accounts (API Keys)
  - Hardware Requirements
- [ ] Subtask 2.2: Ergänze PostgreSQL + pgvector Installation
  - pacman Commands
  - pgvector from Source
  - Database/User Creation Commands
- [ ] Subtask 2.3: Ergänze Python Environment Setup
  - venv Creation
  - Poetry/pip Install
  - .env Configuration
- [ ] Subtask 2.4: Ergänze Database Migrations Section
  - Migration Commands
  - Verification Steps
- [ ] Subtask 2.5: Ergänze MCP Server Configuration
  - Server Start Commands
  - Claude Code Integration (mcp-settings.json Beispiel)
  - Verification Test (ping → pong)
- [ ] Subtask 2.6: Ergänze Verification Checklist
  - 6 Verification Items als Markdown Checklist

### Task 3: Create Operations Manual (AC: 3.12.3)

- [ ] Subtask 3.1: Erstelle `/docs/operations-manual.md` mit Service Management
  - systemctl Commands (start, stop, restart, status)
  - journalctl Log Commands
- [ ] Subtask 3.2: Ergänze Backup Operations Section
  - pg_dump Commands
  - Backup Verification
  - Retention Policy
- [ ] Subtask 3.3: Ergänze Model Drift Detection Section
  - Manuelle Drift Check Commands/Queries
  - Cron Job Status Check
  - Alert Interpretation
- [ ] Subtask 3.4: Ergänze Budget Monitoring Section
  - CLI Commands (budget dashboard, breakdown)
  - Alert Thresholds
  - Cost Interpretation
- [ ] Subtask 3.5: Ergänze Ground Truth Maintenance
  - Streamlit UI Start Command
  - Labeling Workflow
  - Dual Judge Review
- [ ] Subtask 3.6: Ergänze Common Operational Tasks
  - Working Memory Management
  - Episode Memory Review
  - L2 Insights Exploration

### Task 4: Create Troubleshooting Guide (AC: 3.12.4)

- [ ] Subtask 4.1: Erstelle `/docs/troubleshooting.md` mit Problem Template
  - Konsistentes Format: Symptom → Checks → Solutions
- [ ] Subtask 4.2: Dokumentiere "MCP Server verbindet nicht" Problem
- [ ] Subtask 4.3: Dokumentiere "Latency >5s" Problem
- [ ] Subtask 4.4: Dokumentiere "API Budget Überschreitung" Problem
- [ ] Subtask 4.5: Dokumentiere "Model Drift Alert" Problem
- [ ] Subtask 4.6: Dokumentiere "PostgreSQL Connection Failure" Problem
- [ ] Subtask 4.7: Dokumentiere "Haiku API Unavailable" Problem
- [ ] Subtask 4.8: Dokumentiere "Low Precision@5" Problem

### Task 5: Create Backup & Recovery Guide (AC: 3.12.5)

- [ ] Subtask 5.1: Erstelle `/docs/operations/backup-recovery.md` mit Strategy Overview
  - Backup Schedule (Daily 3 AM)
  - Retention (7 days)
  - Location
- [ ] Subtask 5.2: Ergänze RTO/RPO Section
  - RTO: <1 hour
  - RPO: <24 hours
- [ ] Subtask 5.3: Ergänze Full Database Restore
  - pg_restore Step-by-Step
  - Verification nach Restore
  - Service Restart
- [ ] Subtask 5.4: Ergänze L2 Insights Git Fallback
  - JSON Loading
  - Embedding Re-Generation
  - Cost Estimation
- [ ] Subtask 5.5: Ergänze Disaster Recovery Checklist
  - 6-Step Checklist

### Task 6: Create API Reference (AC: 3.12.6)

- [ ] Subtask 6.1: Erstelle `/docs/api-reference.md` mit Tools Section Header
- [ ] Subtask 6.2: Dokumentiere store_raw_dialogue Tool
  - Parameters, Response, Example, Errors
- [ ] Subtask 6.3: Dokumentiere compress_to_l2_insight Tool
- [ ] Subtask 6.4: Dokumentiere hybrid_search Tool
- [ ] Subtask 6.5: Dokumentiere update_working_memory Tool
- [ ] Subtask 6.6: Dokumentiere store_episode Tool
- [ ] Subtask 6.7: Dokumentiere get_golden_test_results Tool
- [ ] Subtask 6.8: Dokumentiere store_dual_judge_scores Tool
- [ ] Subtask 6.9: Erstelle Resources Section
  - 5 Resources mit URI, Parameters, Response, Example
- [ ] Subtask 6.10: Ergänze Code Snippets Section
  - Claude Code Beispiele
  - Best Practices

### Task 7: Code Documentation Review (AC: 3.12.7)

- [ ] Subtask 7.1: Review Python Docstrings in mcp_server/tools/
  - Verifiziere alle wichtigen Funktionen haben Docstrings
  - Liste fehlende Docstrings
- [ ] Subtask 7.2: Review Python Docstrings in mcp_server/resources/
- [ ] Subtask 7.3: Review Python Docstrings in mcp_server/external/
- [ ] Subtask 7.4: Review Python Docstrings in mcp_server/utils/
- [ ] Subtask 7.5: Ergänze fehlende Docstrings (falls vorhanden)
- [ ] Subtask 7.6: Review Inline Comments für komplexe Logik
  - RRF Fusion (rrf_fusion.py)
  - Kappa Calculation (dual_judge)
  - Hybrid Search Algorithm
- [ ] Subtask 7.7: Review config.yaml Kommentare
- [ ] Subtask 7.8: Review .env.template Dokumentation
- [ ] Subtask 7.9: Review SQL Migration Kommentare

### Task 8: Final Documentation Review & Integration (AC: All)

- [ ] Subtask 8.1: Cross-Reference Check
  - Alle Links zwischen Docs funktionieren
  - Konsistente Terminologie
- [ ] Subtask 8.2: Language Consistency Check
  - Alle Docs in Deutsch (document_output_language)
  - Code Comments in Englisch (Standard)
- [ ] Subtask 8.3: Create /docs/index.md (optional)
  - Index aller Dokumentations-Dateien
  - Quick Navigation
- [ ] Subtask 8.4: Final Proofread
  - Rechtschreibung
  - Formatierung (Markdown valid)
  - Command Beispiele verifizieren</tasks>
  </story>

  <acceptanceCriteria>### AC-3.12.1: README.md - Projekt-Overview

**Given** das System ist vollständig implementiert (Epic 1-3 complete)
**When** Dokumentation finalisiert wird
**Then** existiert `/docs/README.md` mit folgenden Sections:

1. **System-Architektur:**
   - High-Level Diagramm (MCP Server + Claude Code + PostgreSQL + APIs)
   - Komponenten-Übersicht (7 Tools, 5 Resources)
   - Datenfluss-Beschreibung (Query → Retrieval → Generation → Evaluation → Reflexion)

2. **Key Features:**
   - L0/L2 Memory Storage
   - Hybrid Search (Semantic + Keyword + RRF)
   - Chain-of-Thought Generation
   - Reflexion Framework (Verbal RL)
   - Model Drift Detection
   - Budget Monitoring

3. **Budget & Performance Metrics:**
   - Expected Cost: €5-10/mo (Phase 1), €2-3/mo (nach Staged Dual Judge)
   - Latency Targets: <5s p95 End-to-End
   - Precision@5: >0.75 target

4. **Quick Start:**
   - Link zu Installation Guide
   - Link zu Operations Manual
   - Minimum Requirements Summary

### AC-3.12.2: Installation Guide - Setup von Scratch

**Given** ein neues System ohne vorhandene Installation
**When** Dokumentation finalisiert wird
**Then** existiert `/docs/installation-guide.md` mit folgenden Sections:

1. **Prerequisites:**
   - System Requirements (OS, Python, PostgreSQL)
   - External Accounts (OpenAI API, Anthropic API, Claude MAX)
   - Hardware Requirements (minimal für Personal Use)

2. **PostgreSQL + pgvector Installation:**
   - Arch Linux Installation Commands
   - pgvector from Source kompilieren
   - Database + User Creation
   - Extension aktivieren

3. **Python Environment Setup:**
   - Virtual Environment erstellen
   - Poetry/pip Dependencies installieren
   - .env Configuration

4. **Database Migrations:**
   - Schema-Migration Commands
   - Verification Steps

5. **MCP Server Configuration:**
   - Server starten und testen
   - Claude Code Integration (`~/.config/claude-code/mcp-settings.json`)
   - Verification: ping → pong Test

6. **Verification Checklist:**
   - [ ] PostgreSQL running
   - [ ] pgvector Extension active
   - [ ] MCP Server starts without errors
   - [ ] Claude Code connects to MCP Server
   - [ ] ping Tool returns "pong"

### AC-3.12.3: Operations Manual - Daily Operations

**Given** das System läuft in Production
**When** Dokumentation finalisiert wird
**Then** existiert `/docs/operations-manual.md` mit folgenden Sections:

1. **Service Management:**
   - MCP Server starten/stoppen/neustarten (`systemctl` Commands)
   - Service Status prüfen
   - Logs anzeigen (`journalctl` Commands)

2. **Backup Operations:**
   - Manuelle Backup Commands (`pg_dump`)
   - Backup Verification
   - Backup Location und Retention

3. **Model Drift Detection:**
   - Manueller Drift Check (Claude Code Query)
   - Cron Job Status prüfen
   - Drift Alert Interpretation

4. **Budget Monitoring:**
   - Daily/Monthly Cost Check Commands
   - Budget Alert Thresholds
   - Cost Breakdown Interpretation

5. **Ground Truth Maintenance:**
   - Streamlit UI starten
   - Neue Queries labeln
   - Dual Judge Scores reviewen

6. **Common Operational Tasks:**
   - Working Memory clearen
   - Episode Memory reviewen
   - L2 Insights explorieren

### AC-3.12.4: Troubleshooting Guide - Common Issues

**Given** Probleme treten während System-Betrieb auf
**When** Dokumentation finalisiert wird
**Then** existiert `/docs/troubleshooting.md` mit folgenden Problem/Solution Pairs:

1. **MCP Server verbindet nicht:**
   - Symptom: Claude Code zeigt keine Tools
   - Checks: systemd status, logs, mcp-settings.json
   - Solutions: Service restart, config validation

2. **Latency >5s:**
   - Symptom: Queries dauern zu lange
   - Checks: Profile Hybrid Search, pgvector Index, API Latency
   - Solutions: Index rebuild, Connection pooling, API retry tuning

3. **API Budget Überschreitung:**
   - Symptom: Budget Alert triggered
   - Checks: api_cost_log breakdown, Reflexion rate
   - Solutions: Reduce query volume, activate Staged Dual Judge

4. **Model Drift Alert:**
   - Symptom: Precision@5 drop >5%
   - Checks: embedding_model_version, Golden Test results
   - Solutions: Re-run Calibration, check OpenAI API changes

5. **PostgreSQL Connection Failure:**
   - Symptom: Database not accessible
   - Checks: PostgreSQL service status, credentials
   - Solutions: Service restart, connection string validation

6. **Haiku API Unavailable:**
   - Symptom: Evaluation failures, fallback mode active
   - Checks: api_retry_log, Anthropic Status Page
   - Solutions: Wait for recovery, manual retry

7. **Low Precision@5:**
   - Symptom: Retrieved documents not relevant
   - Checks: Query types, L2 Insight quality, Hybrid weights
   - Solutions: Re-calibration, more Ground Truth, L2 Compression review

### AC-3.12.5: Backup & Recovery Guide

**Given** Daten müssen wiederhergestellt werden
**When** Dokumentation finalisiert wird
**Then** existiert `/docs/operations/backup-recovery.md` mit folgenden Sections:

1. **Backup Strategy Overview:**
   - pg_dump Daily Backups (3 AM Cron)
   - 7-Day Retention Policy
   - Backup Location: `/backups/postgres/`

2. **Recovery Time/Point Objectives:**
   - RTO: <1 hour
   - RPO: <24 hours

3. **Full Database Restore:**
   - Step-by-Step `pg_restore` Commands
   - Verification Steps nach Restore
   - Service Restart Sequence

4. **L2 Insights Git Fallback:**
   - JSON Export Loading
   - Embedding Re-Generation via OpenAI API
   - Cost Estimation für Re-Generation

5. **Partial Recovery Scenarios:**
   - Single Table Restore
   - Point-in-Time Recovery (falls WAL enabled)

6. **Disaster Recovery Checklist:**
   - [ ] Stop MCP Server
   - [ ] Backup current (corrupted) state
   - [ ] Restore from latest backup
   - [ ] Verify data integrity
   - [ ] Restart MCP Server
   - [ ] Run health checks

### AC-3.12.6: API Reference - MCP Tools & Resources

**Given** Entwickler will MCP Tools/Resources verstehen
**When** Dokumentation finalisiert wird
**Then** existiert `/docs/api-reference.md` mit folgenden Sections:

1. **MCP Tools Reference (7 Tools):**

   Für jedes Tool:
   - Tool Name und Zweck
   - Parameter (Name, Type, Required, Description)
   - Response Format
   - Example Usage in Claude Code
   - Error Codes

   Tools:
   - `store_raw_dialogue`
   - `compress_to_l2_insight`
   - `hybrid_search`
   - `update_working_memory`
   - `store_episode`
   - `get_golden_test_results`
   - `store_dual_judge_scores`

2. **MCP Resources Reference (5 Resources):**

   Für jede Resource:
   - URI Schema
   - Query Parameters
   - Response Format
   - Example Usage

   Resources:
   - `memory://l2-insights`
   - `memory://working-memory`
   - `memory://episode-memory`
   - `memory://l0-raw`
   - `memory://stale-memory`

3. **Code Snippets:**
   - Claude Code Beispiele für häufige Operationen
   - Error Handling Patterns
   - Best Practices

### AC-3.12.7: Code Documentation Quality

**Given** Codebase ist implementiert
**When** Dokumentation finalisiert wird
**Then** sind folgende Code-Dokumentations-Standards erfüllt:

1. **Python Docstrings:**
   - Alle wichtigen Funktionen haben Docstrings
   - Format: Google-Style oder NumPy-Style (konsistent)
   - Parameter, Return Values, Exceptions dokumentiert

2. **Inline Comments:**
   - Komplexe Logik (RRF Fusion, Kappa Calculation) hat Inline-Comments
   - Algorithms erklärt (Hybrid Search, LRU Eviction)
   - Magic Numbers erklärt

3. **Config File Comments:**
   - `config.yaml` hat Kommentare für jede Variable
   - `.env.template` dokumentiert alle erforderlichen Variablen

4. **Schema Documentation:**
   - SQL Migrations haben Kommentare
   - Tabellen-Zweck dokumentiert</acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>bmad-docs/architecture.md</path>
        <title>Cognitive Memory System v3.1.0-Hybrid - Architektur</title>
        <section>System Architecture & Components</section>
        <snippet>High-Level Architektur mit MCP Server + Claude Code + PostgreSQL + APIs. Komponenten-Übersicht: 7 Tools, 5 Resources. Datenfluss: Query → Retrieval → Generation → Evaluation → Reflexion</snippet>
      </doc>
      <doc>
        <path>bmad-docs/tech-spec-epic-3.md</path>
        <title>Epic Technical Specification: Working Memory, Evaluation & Production Readiness</title>
        <section>Production Monitoring & Reliability</section>
        <snippet>Epic 3 implementiert Production Readiness Layer mit Golden Test Set (50-100 Queries), Model Drift Detection (täglich), API Retry Logic mit Exponential Backoff (4 Retries), Budget Monitoring Dashboard und 7-Day Stability Testing</snippet>
      </doc>
      <doc>
        <path>bmad-docs/architecture.md</path>
        <title>Cognitive Memory System v3.1.0-Hybrid - Architektur</title>
        <section>Datenbank-Schema</section>
        <snippet>PostgreSQL Schema mit 10 Tabellen: l0_raw, l2_insights, working_memory, episode_memory, stale_memory, ground_truth, golden_test_set, model_drift_log, api_cost_log, api_retry_log</snippet>
      </doc>
      <doc>
        <path>bmad-docs/architecture.md</path>
        <title>Cognitive Memory System v3.1.0-Hybrid - Architektur</title>
        <section>MCP Tools & Resources</section>
        <snippet>7 MCP Tools (store_raw_dialogue, compress_to_l2_insight, hybrid_search, update_working_memory, store_episode, get_golden_test_results, store_dual_judge_scores) und 5 MCP Resources (memory://l2-insights, working-memory, episode-memory, l0-raw, stale-memory)</snippet>
      </doc>
      <doc>
        <path>bmad-docs/architecture.md</path>
        <title>Cognitive Memory System v3.1.0-Hybrid - Architektur</title>
        <section>Development Environment Setup</section>
        <snippet>Installation Commands für PostgreSQL + pgvector, Python Environment, Environment Configuration, Database Migrations, MCP Server Test, Claude Code Integration mit mcp-settings.json</snippet>
      </doc>
      <doc>
        <path>bmad-docs/architecture.md</path>
        <title>Cognitive Memory System v3.1.0-Hybrid - Architektur</title>
        <section>Backup & Disaster Recovery</section>
        <snippet>PostgreSQL Backups: pg_dump -Fc, Daily 3 AM Cron, 7-day Retention, Location: /backups/postgres/. L2 Insights Git Export (optional). RTO: <1 hour, RPO: <24 hours</snippet>
      </doc>
      <doc>
        <path>bmad-docs/tech-spec-epic-3.md</path>
        <title>Epic Technical Specification: Working Memory, Evaluation & Production Readiness</title>
        <section>Data Models and Contracts</section>
        <snippet>4 neue PostgreSQL Tabellen für Epic 3: golden_test_set (id, query, expected_docs, query_type), model_drift_log (date, precision_at_5, drift_detected), api_cost_log (date, api_name, estimated_cost), api_retry_log (timestamp, api_name, retry_count)</snippet>
      </doc>
      <doc>
        <path>bmad-docs/tech-spec-epic-3.md</path>
        <title>Epic Technical Specification: Working Memory, Evaluation & Production Readiness</title>
        <section>APIs and Interfaces</section>
        <snippet>Enhanced API Retry Logic mit Exponential Backoff (4 Retries: 1s, 2s, 4s, 8s), Claude Code Fallback bei Haiku API Ausfall, Model Drift Detection API mit täglicher Precision@5 Validierung</snippet>
      </doc>
      <doc>
        <path>bmad-docs/tech-spec-epic-3.md</path>
        <title>Epic Technical Specification: Working Memory, Evaluation & Production Readiness</title>
        <section>Workflows and Sequencing</section>
        <snippet>5 Key Workflows: Daily Model Drift Detection, API Retry + Fallback, Daily Backup + L2 Export, Staged Dual Judge Transition, 7-Day Stability Testing mit 168h Uptime</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>mcp_server/tools/get_golden_test_results.py</path>
        <kind>tool</kind>
        <symbol>execute_golden_test</symbol>
        <lines>69-338</lines>
        <reason>Core Golden Test execution function for daily model drift detection, calculates Precision@5, detects drift with 7-day rolling average baseline</reason>
      </artifact>
      <artifact>
        <path>config/config.yaml</path>
        <kind>configuration</kind>
        <symbol>base.memory, api_limits, budget, staged_dual_judge</symbol>
        <lines>21-256</lines>
        <reason>Production configuration with hybrid search weights, API retry logic, budget monitoring, staged dual judge settings, environment separation</reason>
      </artifact>
      <artifact>
        <path>.env.template</path>
        <kind>configuration</kind>
        <symbol>ENVIRONMENT, API_KEYS, POSTGRESQL, LOGGING</symbol>
        <lines>1-84</lines>
        <reason>Environment variables template for API keys, database connection, logging configuration. Required for production setup.</reason>
      </artifact>
      <artifact>
        <path>mcp_server/utils/retry_logic.py</path>
        <kind>utility</kind>
        <symbol>exponential_backoff_retry</symbol>
        <reason>Enhanced retry logic with exponential backoff (1s, 2s, 4s, 8s), jitter support, and retry logging for all external APIs</reason>
      </artifact>
      <artifact>
        <path>mcp_server/budget/budget_monitor.py</path>
        <kind>component</kind>
        <symbol>BudgetMonitor</symbol>
        <reason>Budget monitoring CLI dashboard with daily/monthly cost tracking, API breakdown, and budget alerts at €8/€10 thresholds</reason>
      </artifact>
      <artifact>
        <path>docs/production-checklist.md</path>
        <kind>documentation</kind>
        <symbol>Production Deployment Checklist</symbol>
        <lines>1-50</lines>
        <reason>Existing production checklist with infrastructure requirements, database setup, environment separation, and deployment verification steps</reason>
      </artifact>
      <artifact>
        <path>docs/budget-monitoring.md</path>
        <kind>documentation</kind>
        <symbol>Budget Monitoring System</symbol>
        <lines>1-30</lines>
        <reason>Existing budget monitoring documentation with CLI dashboard usage, cost tracking, and optimization recommendations</reason>
      </artifact>
    </code>
    <dependencies>
      <framework name="Poetry Dependency Management" kind="python-package-manager" artifact="pyproject.toml">
        Production project uses Poetry for dependency management. Core dependencies: mcp>=1.0.0, psycopg2-binary>=2.9.0, pgvector>=0.2.0, openai>=1.0.0, anthropic>=0.25.0. Dev dependencies: black, ruff, mypy, pytest.
      </framework>
      <framework name="MCP Server Framework" kind="server-framework" artifact="mcp>=1.0.0">
        Model Context Protocol server framework for Claude Code integration. Provides tools and resources interfaces. All tools follow hybrid pattern with core function + MCP wrapper.
      </framework>
      <framework name="PostgreSQL + pgvector" kind="database" artifact="psycopg2-binary>=2.9.0, pgvector>=0.2.0">
        PostgreSQL database with pgvector extension for vector similarity search. Uses <-> operator with HNSW indexes for performance. Environment separation: dev=cognitive_memory_dev, prod=cognitive_memory.
      </framework>
      <framework name="OpenAI & Anthropic APIs" kind="external-apis" artifact="openai>=1.0.0, anthropic>=0.25.0">
        OpenAI API for embeddings (text-embedding-3-small, 1536 dimensions). Anthropic API for Haiku evaluation (claude-3-5-haiku-20241022) and GPT-4o judging. All calls use exponential_backoff_retry with 4 attempts.
      </framework>
      <framework name="Streamlit UI Framework" kind="ui-framework" artifact="streamlit>=1.28.0">
        Used for Ground Truth labeling UI and Golden Test Set management. Interactive web interface for relevance labeling and IRR validation.
      </framework>
      <framework name="Python Code Quality" kind="code-quality" artifact="black>=23.0.0, ruff>=0.1.0, mypy>=1.7.0">
        Black for code formatting (88 character line length). Ruff for linting. MyPy for type checking (relaxed settings for now). Pre-commit hooks for code quality enforcement.
      </framework>
      <framework name="Pytest Testing Framework" kind="testing-framework" artifact="pytest>=7.4.0, pytest-cov>=4.1.0">
        Unit and integration testing framework with coverage reporting. Tests in tests/ directory. Test discovery for test_*.py and *_test.py files.
      </framework>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint type="development-pattern">All MCP Tools follow hybrid pattern: Core function (direct Python callable) + MCP Wrapper (protocol callable). Core functions can be called via cron/scripts without MCP overhead.</constraint>
    <constraint type="environment-separation">Development uses cognitive_memory_dev database, production uses cognitive_memory. Config loaded via ENVIRONMENT variable with base+environment merge pattern.</constraint>
    <constraint type="api-retry">All external API calls must use exponential_backoff_retry with 4 attempts (1s, 2s, 4s, 8s delays) and jitter to prevent thundering herd.</constraint>
    <constraint type="budget-monitoring">All API calls must log to api_cost_log table with estimated_cost calculation using config.yaml api_cost_rates. Alert at 80% of €10 monthly limit.</constraint>
    <constraint type="documentation-language">User-facing documentation must be in German (document_output_language). Code comments and API documentation in English.</constraint>
    <constraint type="postgresql-extensions">pgvector extension must be enabled for vector operations. All vector queries use <-> operator with cosine similarity.</constraint>
    <constraint type="security">API keys only in .env files (git-ignored, chmod 600). No hardcoded secrets in source code. MCP Server runs as non-root user.</constraint>
  </constraints>
  <interfaces>
    <interface name="MCP Tool: get_golden_test_results" kind="MCP Tool" signature="handle_get_golden_test_results(arguments: dict) -> dict" path="mcp_server/tools/get_golden_test_results.py">
      Daily model drift detection tool. Returns precision_at_5, drift_detected, baseline metrics. Called via MCP protocol or execute_golden_test() for cron jobs.
    </interface>
    <interface name="Budget Monitoring CLI" kind="Command Line" signature="python -m mcp_server.budget --days 30" path="mcp_server/budget/cli.py">
      Interactive dashboard showing daily/monthly API costs, projected monthly cost, breakdown by API, and budget alerts. Essential for NFR003 compliance.
    </interface>
    <interface name="PostgreSQL Connection" kind="Database" signature="postgresql://user:password@host:port/database" path="mcp_server/db/connection.py">
      Connection pooling with environment-specific databases. Development: cognitive_memory_dev, Production: cognitive_memory. Supports pgvector operations.
    </interface>
    <interface name="Environment Configuration" kind="YAML Config" signature="config.yaml (base + development/production sections)" path="config/config.yaml">
      Hierarchical configuration loading: base configuration merged with environment-specific section based on ENVIRONMENT variable. Includes all system parameters.
    </interface>
  </interfaces>
  <tests>
    <standards>
      <standard type="unit-tests" description=">80% code coverage required for critical functions (retry logic, precision calculation, config parsing). Tests use pytest framework with fixtures for database isolation. All MCP tools have both unit tests and integration tests.">
        pytest framework with test_*.py and *_test.py discovery. Coverage measured via pytest-cov. Mock external API calls (OpenAI, Anthropic) in unit tests. Database tests use isolated test databases.
      </standard>
      <standard type="integration-tests" description="Key workflows validated: Golden Test execution, API retry+fallback, backup/restore, budget monitoring. Use Docker for PostgreSQL isolation. Test both development and production configurations.">
        Integration tests validate component interactions. Test backup/restore workflow with real pg_dump/pg_restore. Test budget monitoring with mock API cost data. Validate retry logic with simulated API failures.
      </standard>
      <standard type="end-to-end-tests" description="7-Day Stability Test (Story 3.11): 168h uptime, 70+ queries, >99% success rate. Validates full RAG pipeline, monitoring systems, and error recovery. Production environment only.">
        End-to-end testing validates complete user scenarios. 7-day stability test is final validation before production sign-off. Monitors uptime, query success rate, latency, budget compliance. Tests all cron jobs (Golden Test, Backup).
      </standard>
    </standards>
    <locations>
      <location type="test-directory" path="tests/">
        Main test directory with unit tests for all MCP tools. Contains test_hybrid_search.py, test_compress_to_l2_insight.py, test_dual_judge.py, test_staged_dual_judge.py, and other component tests.
      </location>
      <location type="manual-tests" path="tests/manual/">
        Manual integration tests for complex workflows. Contains test_evaluation_story_2_5.py and test_reflexion_story_2_6.py for Epic 2 validation.
      </location>
      <location type="validation-scripts" path="mcp_server/scripts/">
        Validation scripts for precision testing and golden test validation. Contains validate_precision_at_5.py, run_golden_test.py, validate_golden_test_set.py for quality assurance.
      </location>
      <location type="benchmarking" path="mcp_server/benchmarking/">
        Performance testing and latency benchmarking tools. Contains latency_benchmark.py for Story 3.5 performance validation (p95 <5s target).
      </location>
    </locations>
    <ideas>
      <idea type="regression-tests" description="Create automated regression test suite using Golden Test Set to detect Precision@5 degradation >5% between deployments.">
        Implement automated regression testing that runs Golden Test Set before each deployment. Compare Precision@5 against baseline to catch model drift or code regressions. Integrate with CI/CD pipeline for automated quality gates.
      </idea>
      <idea type="performance-tests" description="Automated performance benchmarks with 100 test queries measuring p50/p95/p99 latency for Hybrid Search, Embedding API calls, and end-to-end RAG pipeline.">
        Create performance test suite with standardized query set (40 short, 40 medium, 20 long). Measure latency breakdown: embedding creation, semantic search, keyword search, RRF fusion, CoT generation, evaluation. Set up alerts when p95 latency exceeds 5s threshold.
      </idea>
      <idea type="budget-tests" description="Mock test scenarios for budget overage detection: simulate €12/mo projected cost and verify alert triggers at 80% threshold.">
        Create budget monitoring test scenarios that simulate various cost patterns. Test alert thresholds (€8 projected monthly) and monthly limit alerts (€10). Validate cost calculation accuracy across all API types and usage patterns.
      </idea>
      <idea type="backup-tests" description="Automated backup/restore testing: create test database, run backup script, restore to new database, verify data integrity with checksums.">
        Implement automated backup validation that creates test data, runs backup script, restores to isolated database, and verifies data integrity. Test both PostgreSQL dump and L2 Insights Git export mechanisms. Validate RTO/RPO targets (<1h restore, <24h data loss).
      </idea>
      <idea type="failure-scenarios" description="Test failure modes: Haiku API outage (verify fallback activation), PostgreSQL connection loss (verify auto-reconnect), disk space full (verify backup rotation).">
        Create chaos engineering test suite for production failure scenarios. Test API retry logic with mock failures. Test fallback mechanisms (Haiku → Claude Code). Test systemd auto-restart after crashes. Validate graceful degradation and recovery procedures.
      </idea>
    </ideas>
  </tests>
</story-context>
