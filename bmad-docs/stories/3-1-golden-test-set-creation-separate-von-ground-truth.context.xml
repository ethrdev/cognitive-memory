<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>3</epicId>
    <storyId>1</storyId>
    <title>Golden Test Set Creation (separate von Ground Truth)</title>
    <status>drafted</status>
    <generatedAt>2025-11-18</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>bmad-docs/stories/3-1-golden-test-set-creation-separate-von-ground-truth.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>Entwickler</asA>
    <iWant>ein separates Golden Test Set (50-100 Queries) erstellen</iWant>
    <soThat>ich tägliche Precision@5 Regression-Tests durchführen kann ohne Ground Truth zu kontaminieren</soThat>
    <tasks>
- Task 1: Database Schema Migration (AC: 3.1.3)
  - Subtask 1.1: Create migration file for golden_test_set table
  - Subtask 1.2: Add query_type column with CHECK constraint
  - Subtask 1.3: Create index on query_type for stratification queries
  - Subtask 1.4: Execute migration on PostgreSQL database

- Task 2: Session Sampling Logic (AC: 3.1.1)
  - Subtask 2.1: Query l0_raw for all unique session_ids
  - Subtask 2.2: Exclude sessions already in ground_truth table
  - Subtask 2.3: Sample 50-100 queries from remaining sessions
  - Subtask 2.4: Classify queries by length (Short/Medium/Long)
  - Subtask 2.5: Ensure stratification (40%/40%/20% distribution)

- Task 3: Streamlit UI Adaptation (AC: 3.1.2)
  - Subtask 3.1: Copy Streamlit UI from Story 1.10
  - Subtask 3.2: Modify to target golden_test_set table
  - Subtask 3.3: Remove Dual Judge UI components (not needed)
  - Subtask 3.4: Add query_type display in UI
  - Subtask 3.5: Test labeling workflow with sample queries

- Task 4: Query Import and Labeling (AC: 3.1.1, 3.1.2)
  - Subtask 4.1: Insert sampled queries into golden_test_set
  - Subtask 4.2: Launch Streamlit UI for manual labeling
  - Subtask 4.3: Label all 50-100 queries with expected_docs
  - Subtask 4.4: Verify all queries have labels (no NULL expected_docs)

- Task 5: Validation and Documentation (AC: 3.1.4)
  - Subtask 5.1: Verify 50-100 queries in golden_test_set
  - Subtask 5.2: Verify stratification (40%/40%/20% achieved)
  - Subtask 5.3: Verify no session overlap with ground_truth
  - Subtask 5.4: Document Golden Test Set creation in README
  - Subtask 5.5: Mark table as immutable in schema comments
    </tasks>
  </story>

  <acceptanceCriteria>
**Given** L0 Raw Memory und L2 Insights existieren
**When** ich Golden Test Set erstelle
**Then** werden 50-100 Queries extrahiert:

1. **AC-3.1.1: Query Extraction und Stratification**
   - Source: Automatisch aus L0 Raw Memory (unterschiedliche Sessions als Ground Truth)
   - Stratification: 40% Short, 40% Medium, 20% Long (gleich wie Ground Truth)
   - Temporal Diversity: Keine Überlappung mit Ground Truth Sessions
   - Expected Size: 50-100 Queries für statistical power >0.80

2. **AC-3.1.2: Manuelle Relevanz-Labeling**
   - Labeling: Manuelle Relevanz-Labels via Streamlit UI (gleiche UI wie Story 1.10)
   - User-Labels: expected_docs Arrays für jede Query
   - Wiederverwendung: Streamlit Code aus Story 1.10 (andere Tabelle)

3. **AC-3.1.3: Golden Test Set Storage**
   - Tabelle: `golden_test_set` (id, query, expected_docs, created_at, query_type)
   - query_type: "short" | "medium" | "long" für Stratification-Tracking
   - Keine judge_scores (kein Dual Judge für Golden Set - nur User-Labels)

4. **AC-3.1.4: Immutability nach Erstellung**
   - Keine Updates nach Initial Labeling (fixed Baseline für Drift Detection)
   - Separates Set verhindert Overfitting auf Ground Truth
   - Rationale: "Teaching to the test" vermeiden
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <!-- Epic 3 Technical Specification -->
      <doc>
        <path>bmad-docs/tech-spec-epic-3.md</path>
        <title>Epic 3 Technical Specification - Production Readiness &amp; Monitoring</title>
        <section>Story 3.1: Golden Test Set Creation</section>
        <snippet>Defines acceptance criteria AC-3.1.1 through AC-3.1.4 including query extraction, stratification (40%/40%/20%), manual labeling via Streamlit UI, golden_test_set table schema, and immutability requirements. Provides detailed database schema with query_type column and indices.</snippet>
      </doc>

      <!-- Epics Definition -->
      <doc>
        <path>bmad-docs/epics.md</path>
        <title>Project Epics - All Stories</title>
        <section>Story 3.1 (lines 887-921)</section>
        <snippet>User story definition: "Als Entwickler möchte ich ein separates Golden Test Set (50-100 Queries) erstellen sodass ich tägliche Precision@5 Regression-Tests durchführen kann." Explains separation from Ground Truth Set, session sampling strategy, and rationale for immutable baseline.</snippet>
      </doc>

      <!-- Architecture Documentation -->
      <doc>
        <path>bmad-docs/architecture.md</path>
        <title>System Architecture</title>
        <section>Database Schema - golden_test_set Table (lines 284-293)</section>
        <snippet>Defines golden_test_set table schema: id SERIAL PRIMARY KEY, query TEXT NOT NULL, expected_docs INTEGER[] NOT NULL, created_at TIMESTAMPTZ, query_type VARCHAR(20) CHECK (query_type IN ('short', 'medium', 'long')). Separate from ground_truth table for model drift detection.</snippet>
      </doc>

      <!-- Previous Story Context -->
      <doc>
        <path>bmad-docs/stories/2-9-precision-5-validation-auf-ground-truth-set.md</path>
        <title>Story 2.9 - Precision@5 Validation</title>
        <section>Completion Notes &amp; Dev Notes</section>
        <snippet>Validation Infrastructure production-ready with validate_precision_at_5.py (423 lines), calculate_precision_at_5() function, classify_query_type() function based on word count. Ground Truth Set structure: 40% Short, 40% Medium, 20% Long stratification. Streamlit UI pattern from Story 1.10 for labeling.</snippet>
      </doc>

      <!-- PRD Reference -->
      <doc>
        <path>bmad-docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>Epic 3 Requirements</section>
        <snippet>Epic 3 Goal: Production Readiness with robust monitoring, API reliability, budget optimization (€5-10/mo), and 7-day stability testing. Golden Test Set is foundation for Model Drift Detection (Story 3.2).</snippet>
      </doc>
    </docs>

    <code>
      <!-- Existing Database Migration -->
      <artifact>
        <path>mcp_server/db/migrations/006_golden_test_set.sql</path>
        <kind>migration</kind>
        <symbol>golden_test_set table</symbol>
        <lines>1-73</lines>
        <reason>EXISTING migration file for golden_test_set table. Already implements schema with query_type CHECK constraint, indices on query_type/created_at/session_id, and SQL comments documenting immutability. Contains validation query to verify no overlap with ground_truth.</reason>
      </artifact>

      <!-- Query Classification Function -->
      <artifact>
        <path>mcp_server/scripts/validate_precision_at_5.py</path>
        <kind>script</kind>
        <symbol>classify_query_type()</symbol>
        <lines>75-100</lines>
        <reason>REUSE this function for query stratification. Classifies queries by word count: Short (≤10 words), Medium (11-29 words), Long (≥30 words). Validated in Story 2.9.</reason>
      </artifact>

      <!-- Precision Calculation Function -->
      <artifact>
        <path>mcp_server/scripts/validate_precision_at_5.py</path>
        <kind>script</kind>
        <symbol>calculate_precision_at_5()</symbol>
        <lines>53-68</lines>
        <reason>REUSE for future Golden Test validation (Story 3.2). Calculates Precision@5 = (relevant_docs_in_top5) / 5. Production-ready and validated.</reason>
      </artifact>

      <!-- Streamlit UI Template -->
      <artifact>
        <path>mcp_server/ui/golden_test_app.py</path>
        <kind>streamlit_app</kind>
        <symbol>Golden Test Set Labeling UI</symbol>
        <lines>1-80</lines>
        <reason>EXISTING Streamlit UI for labeling Golden Test queries. Implements binary relevance labeling, progress tracking, mock mode support. Adapt to remove Dual Judge components, add query_type display, target golden_test_set table.</reason>
      </artifact>

      <!-- Database Connection Pool -->
      <artifact>
        <path>mcp_server/db/connection.py</path>
        <kind>module</kind>
        <symbol>initialize_pool(), get_connection()</symbol>
        <lines>1-50</lines>
        <reason>REUSE for PostgreSQL connection pooling. Provides connection management, health checks, and graceful shutdown. Use for session sampling queries and data insertion.</reason>
      </artifact>

      <!-- Previous Migrations Reference -->
      <artifact>
        <path>mcp_server/db/migrations/002_dual_judge_schema.sql</path>
        <kind>migration</kind>
        <symbol>ground_truth table</symbol>
        <lines>all</lines>
        <reason>REFERENCE for understanding ground_truth table structure. golden_test_set must have NO overlap with sessions in ground_truth. Use for session exclusion logic.</reason>
      </artifact>
    </code>

    <dependencies>
      <python>
        <package name="psycopg2-binary" version="^2.9.0" purpose="PostgreSQL database driver"/>
        <package name="pgvector" version="^0.2.0" purpose="pgvector extension for vector operations"/>
        <package name="streamlit" version="^1.28.0" purpose="Streamlit UI for manual labeling"/>
        <package name="pyyaml" version="^6.0" purpose="Config file parsing"/>
        <package name="python-dotenv" version="^1.0.0" purpose="Environment variable management"/>
        <package name="numpy" version="^1.24.0" purpose="Array operations"/>
        <package name="scipy" version="^1.11.0" purpose="Statistical functions"/>
      </python>

      <dev_dependencies>
        <package name="pytest" version="^7.4.0" purpose="Testing framework"/>
        <package name="black" version="^23.0.0" purpose="Code formatting"/>
        <package name="ruff" version="^0.1.0" purpose="Linting"/>
        <package name="mypy" version="^1.7.0" purpose="Type checking"/>
      </dev_dependencies>

      <database>
        <system>PostgreSQL 15+</system>
        <extensions>
          <extension name="pgvector" purpose="Vector similarity search for L2 Insights embeddings"/>
          <extension name="uuid-ossp" purpose="UUID generation for session_ids"/>
        </extensions>
      </database>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>
      <type>Architecture</type>
      <rule>MUST use existing database connection pool (mcp_server/db/connection.py). DO NOT create new connection management.</rule>
      <source>bmad-docs/architecture.md - Database Connection section</source>
    </constraint>

    <constraint>
      <type>Data Integrity</type>
      <rule>Golden Test Set MUST have ZERO overlap with Ground Truth sessions. Verify via SQL query: SELECT COUNT(*) FROM golden_test_set gts INNER JOIN ground_truth gt ON gts.session_id = gt.session_id (expected: 0 rows).</rule>
      <source>bmad-docs/tech-spec-epic-3.md - AC-3.1.1</source>
    </constraint>

    <constraint>
      <type>Immutability</type>
      <rule>Golden Test Set is IMMUTABLE after initial labeling. NO updates, NO deletions. Only INSERT operations allowed during creation phase.</rule>
      <source>bmad-docs/epics.md Story 3.1, lines 908-910</source>
    </constraint>

    <constraint>
      <type>Stratification</type>
      <rule>Query distribution MUST match Ground Truth: 40% Short (≤10 words), 40% Medium (11-29 words), 20% Long (≥30 words). Tolerance: ±5% per category.</rule>
      <source>bmad-docs/tech-spec-epic-3.md - AC-3.1.1</source>
    </constraint>

    <constraint>
      <type>Code Style</type>
      <rule>Follow existing patterns: snake_case for functions/variables, PascalCase for classes, Black formatting (line-length=88), Ruff linting enabled.</rule>
      <source>pyproject.toml - tool.black, tool.ruff sections</source>
    </constraint>

    <constraint>
      <type>Testing</type>
      <rule>Manual testing for Story 3.1 (database migration + UI labeling). Automated testing deferred. Verify: migration success, 50-100 queries, stratification ±5%, no session overlap.</rule>
      <source>bmad-docs/stories/3-1-golden-test-set-creation-separate-von-ground-truth.md#Testing-Strategy</source>
    </constraint>

    <constraint>
      <type>Reuse Over Recreate</type>
      <rule>REUSE classify_query_type() from validate_precision_at_5.py for stratification. DO NOT reimplement query classification logic.</rule>
      <source>Story 2.9 Dev Notes - Learnings from Previous Story</source>
    </constraint>
  </constraints>

  <interfaces>
    <!-- Database Schema Interface -->
    <interface>
      <name>golden_test_set table</name>
      <kind>database_table</kind>
      <signature>
CREATE TABLE golden_test_set (
    id SERIAL PRIMARY KEY,
    query TEXT NOT NULL,
    query_type VARCHAR(10) NOT NULL CHECK (query_type IN ('short', 'medium', 'long')),
    expected_docs INTEGER[] NOT NULL,
    session_id UUID,
    created_at TIMESTAMP DEFAULT NOW(),
    word_count INTEGER,
    labeled_by VARCHAR(50) DEFAULT 'ethr',
    notes TEXT
);
CREATE INDEX idx_golden_query_type ON golden_test_set(query_type);
CREATE INDEX idx_golden_created_at ON golden_test_set(created_at);
CREATE INDEX idx_golden_session_id ON golden_test_set(session_id);
      </signature>
      <path>mcp_server/db/migrations/006_golden_test_set.sql</path>
    </interface>

    <!-- Query Classification Function -->
    <interface>
      <name>classify_query_type</name>
      <kind>function</kind>
      <signature>
def classify_query_type(query: str) -> str:
    """
    Classify query by length (Story 2.9 requirement)

    Classification:
    - Short: ≤10 words
    - Medium: 11-29 words
    - Long: ≥30 words

    Args:
        query: Query text

    Returns:
        "short" | "medium" | "long"
    """
      </signature>
      <path>mcp_server/scripts/validate_precision_at_5.py:75-100</path>
    </interface>

    <!-- Precision Calculation Function -->
    <interface>
      <name>calculate_precision_at_5</name>
      <kind>function</kind>
      <signature>
def calculate_precision_at_5(retrieved_ids: List[int], expected_ids: List[int]) -> float:
    """
    Calculate Precision@5 metric (REUSED from Story 2.8)

    Formula: (relevant_docs_in_top5) / 5

    Args:
        retrieved_ids: Top-5 L2 Insight IDs from hybrid_search
        expected_ids: Relevant L2 IDs from Ground Truth

    Returns:
        Float 0.0-1.0 (0.0 = no relevant docs, 1.0 = all 5 relevant)
    """
      </signature>
      <path>mcp_server/scripts/validate_precision_at_5.py:53-68</path>
    </interface>

    <!-- Database Connection Interface -->
    <interface>
      <name>get_connection</name>
      <kind>function</kind>
      <signature>
@contextmanager
def get_connection() -> Iterator[connection]:
    """
    Get a database connection from the pool (context manager).

    Yields:
        psycopg2 connection with DictCursor

    Raises:
        PoolError: If connection pool is exhausted
    """
      </signature>
      <path>mcp_server/db/connection.py</path>
    </interface>

    <!-- Session Sampling SQL Query Template -->
    <interface>
      <name>Session Exclusion Query</name>
      <kind>sql_query</kind>
      <signature>
-- Get sessions NOT in ground_truth
SELECT DISTINCT session_id
FROM l0_raw
WHERE session_id NOT IN (
    SELECT DISTINCT session_id
    FROM ground_truth
)
ORDER BY session_id;
      </signature>
      <path>bmad-docs/stories/3-1-golden-test-set-creation-separate-von-ground-truth.md#Session-Sampling-Strategy</path>
    </interface>
  </interfaces>

  <tests>
    <standards>
Story 3.1 uses Manual Testing (database migration + UI labeling workflow). Automated testing is out of scope for this story. Testing approach follows Story 1.10 pattern (Ground Truth UI labeling). Success criteria: (1) Migration runs successfully (no SQL errors), (2) 50-100 queries imported, (3) All queries labeled (no NULL expected_docs), (4) Stratification achieved (40%/40%/20% ±5%), (5) No session overlap verified.

Testing Framework: pytest (for future automated tests)
Code Quality: Black formatting (line-length=88), Ruff linting
Type Checking: mypy (partial - see pyproject.toml overrides)
    </standards>

    <locations>
      <pattern>tests/</pattern>
      <pattern>tests/manual/</pattern>
      <pattern>mcp_server/scripts/validate_*.py</pattern>
    </locations>

    <ideas>
      <test id="AC-3.1.1" description="Verify Query Extraction and Stratification">
        - Manual: Run session sampling script and verify output query distribution
        - Check: 40% Short (±5%), 40% Medium (±5%), 20% Long (±5%)
        - Verify: No duplicate queries
        - Verify: All queries from sessions NOT in ground_truth
      </test>

      <test id="AC-3.1.2" description="Verify Manual Labeling Workflow">
        - Manual: Launch Streamlit UI (streamlit run mcp_server/ui/golden_test_app.py)
        - Test: Label sample of 5-10 queries
        - Verify: expected_docs arrays saved correctly
        - Verify: UI displays query_type field
        - Verify: Progress tracking works
      </test>

      <test id="AC-3.1.3" description="Verify Database Schema and Storage">
        - Run migration: psql -U mcp_user -d cognitive_memory -f mcp_server/db/migrations/006_golden_test_set.sql
        - Verify: Table created successfully
        - Verify: CHECK constraint on query_type works (test invalid value)
        - Verify: Indices created (idx_golden_query_type, idx_golden_created_at, idx_golden_session_id)
        - SQL: \d golden_test_set to inspect schema
      </test>

      <test id="AC-3.1.4" description="Verify Immutability and No Overlap">
        - Verify: No session overlap with ground_truth (SQL query returns 0 rows)
        - SQL: SELECT COUNT(*) FROM golden_test_set gts INNER JOIN ground_truth gt ON gts.session_id = gt.session_id
        - Verify: 50-100 queries in golden_test_set
        - SQL: SELECT COUNT(*) FROM golden_test_set
        - Verify: All queries have expected_docs (no NULLs)
        - SQL: SELECT COUNT(*) FROM golden_test_set WHERE expected_docs IS NULL
      </test>

      <test id="Edge-Cases" description="Test Edge Cases and Error Handling">
        - Empty L0 Raw Memory: Verify script halts with clear error
        - All Sessions in Ground Truth: Verify script warns and suggests alternatives
        - Insufficient Queries for Stratification: Verify script warns (e.g., only 30 Long queries available)
      </test>
    </ideas>
  </tests>
</story-context>
