<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>1</epicId>
    <storyId>3</storyId>
    <title>MCP Server Grundstruktur mit Tool/Resource Framework</title>
    <status>drafted</status>
    <generatedAt>2025-11-12</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>bmad-docs/stories/1-3-mcp-server-grundstruktur-mit-tool-resource-framework.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>Entwickler</asA>
    <iWant>die MCP Server-Grundstruktur mit Tool- und Resource-Registration implementieren</iWant>
    <soThat>Claude Code den Server erreichen und Tools/Resources entdecken kann</soThat>
    <tasks>
      - MCP Server Main Entry Point erstellen (AC: 1, 4)
        * __main__.py als Entry Point (WICHTIG: mit Underscores, NICHT main.py!)
        * Server-Instanz und stdio transport
        * Signal Handlers für SIGTERM/SIGINT (Graceful Shutdown)
        * Logging Configuration (JSON Structured Logging)

      - Database Connection Pool Modul (AC: 4)
        * mcp_server/db/connection.py mit psycopg2.pool.SimpleConnectionPool
        * get_connection() als Context Manager
        * Error Handling: Pool exhausted, Connection timeout, Health check
        * close_all_connections() mit timeout

      - Tool Registration System implementieren (AC: 2)
        * Tool Registry mit JSON Schema Validation
        * 7 Tool-Stubs registrieren: store_raw_dialogue, compress_to_l2_insight, hybrid_search, update_working_memory, store_episode, store_dual_judge_scores, ping
        * Placeholder-Responses für alle Stubs

      - Resource Registration System implementieren (AC: 3)
        * Resource Registry mit URI-Schema memory://
        * 5 Resource-Stubs: memory://l2-insights, memory://working-memory, memory://episode-memory, memory://l0-raw, memory://status
        * Placeholder-Responses für alle Stubs

      - Dummy-Tool ping implementieren (AC: 5)
        * Tool-Definition mit return {"response": "pong"}

      - Dummy-Resource memory://status implementieren (AC: 5)
        * DB Connection Health Check + Server Uptime

      - Integration Tests schreiben (AC: 5)
        * tests/test_mcp_server.py mit subprocess-based testing
        * Tests: Server Start, Handshake, list_tools(), list_resources(), call_tool("ping"), read_resource("memory://status"), SIGTERM

      - .env.development update (AC: 1, 4)
        * LOG_LEVEL Variable hinzufügen

      - MCP Config für Claude Code dokumentieren (AC: 1)
        * README.md Sektion mit Config-Example

      - Dokumentation aktualisieren (AC: 1, 2, 3, 4, 5)
        * MCP Server Setup-Anleitung, Protocol Basics, Troubleshooting, Development Guide, Testing Guide
    </tasks>
  </story>

  <acceptanceCriteria>
    Given: PostgreSQL läuft und Projekt-Setup ist abgeschlossen (Story 1.1 und 1.2 done)
    When: ich den MCP Server starte
    Then:

    1. MCP Server Start und Erreichbarkeit
       - Server startet via stdio transport (Standard für lokale MCP Server)
       - Server antwortet auf MCP Handshake (protocol version, capabilities)
       - Claude Code kann Server in MCP Settings hinzufügen (~/.config/claude-code/mcp-settings.json)
       - Server loggt eingehende Requests (Structured Logging mit JSON)

    2. Tool Registration Framework
       - Tool Registration System implementiert (Decorator-basiert oder Registry-Pattern)
       - 7 Tool-Stubs registriert (gemäß Tech-Spec AC-1.3: list_tools() returns 7 tools)
       - Tool-Stubs geben Placeholder-Responses zurück
       - Error Handling für ungültige Tool-Calls (Parameter-Validierung)
       - JSON Schema für Parameter-Validierung

    3. Resource Registration Framework
       - Resource Registration System mit URI-Schema memory://
       - 5 Resource-Stubs registriert (gemäß Tech-Spec AC-1.3: list_resources() returns 5 resources)
       - Resource URIs folgen Schema: memory://l2-insights, memory://working-memory, etc.
       - Read-Only State Exposure (keine Mutations via Resources)

    4. Database Connection Pool
       - Connection Pool Modul mcp_server/db/connection.py erstellt
       - psycopg2 Connection Pool mit min_conn=1, max_conn=10
       - Environment Variables aus .env.development geladen
       - Connection Health Check Funktion
       - Graceful shutdown (close all connections)

    5. Testing und Validation
       - MCP Inspector kann Server erreichen (handshake erfolgreich)
       - Mindestens 1 Dummy-Tool zum Testing: ping Tool (gibt "pong" zurück)
       - Mindestens 1 Dummy-Resource zum Testing: memory://status (zeigt DB-Connection Status)
       - Integration-Test: Server Start → Handshake → Tool Call → Resource Read → Shutdown
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>bmad-docs/tech-spec-epic-1.md</path>
        <title>Epic Technical Specification: MCP Server Foundation</title>
        <section>Overview + System Architecture Alignment</section>
        <snippet>Epic 1 implementiert einen Python MCP Server mit 7 Tools und 5 Resources. Transport: stdio (MCP Standard für lokale Server). Programming Language: Python 3.11+ mit Type Hints. No Multi-Threading: Sequential Processing.</snippet>
      </doc>
      <doc>
        <path>bmad-docs/tech-spec-epic-1.md</path>
        <title>Epic Technical Specification</title>
        <section>Detailed Design - Services and Modules</section>
        <snippet>MCP Server Core: MCP Protocol Handshake, Tool/Resource Registration, Request Routing. Database Connection Pool: PostgreSQL Connection Management mit psycopg2 Connection Objects (Story 1.2).</snippet>
      </doc>
      <doc>
        <path>bmad-docs/tech-spec-epic-1.md</path>
        <title>Epic Technical Specification</title>
        <section>Code Examples - MCP Server Skeleton</section>
        <snippet>Tool Registration: @server.list_tools() mit list[Tool]. Resource Registration: @server.list_resources() mit list[Resource]. Server Start: async with stdio_server() für stdio transport.</snippet>
      </doc>
      <doc>
        <path>bmad-docs/tech-spec-epic-1.md</path>
        <title>Epic Technical Specification</title>
        <section>Acceptance Criteria - AC-1.3</section>
        <snippet>MCP Server startet via stdio transport. 7 Tools registriert (list_tools() response). 5 Resources registriert (list_resources() response). MCP Inspector kann Server erreichen (handshake erfolgreich).</snippet>
      </doc>
      <doc>
        <path>bmad-docs/architecture.md</path>
        <title>Cognitive Memory System v3.1.0-Hybrid - Architektur</title>
        <section>Systemarchitektur - High-Level Architektur</section>
        <snippet>Claude Code (Sonnet 4.5) verbindet sich via MCP Protocol (stdio transport) zum Python MCP Server (lokal). MCP Server hat 7 Tools, 5 Resources und greift auf PostgreSQL + pgvector zu.</snippet>
      </doc>
      <doc>
        <path>bmad-docs/architecture.md</path>
        <title>Cognitive Memory System - Architektur</title>
        <section>Technologie-Entscheidungen</section>
        <snippet>MCP Server Framework: Python MCP SDK (Latest, pip install mcp) für stdio transport. Datenbank: PostgreSQL 15+ mit pgvector Extension.</snippet>
      </doc>
      <doc>
        <path>bmad-docs/stories/1-2-postgresql-pgvector-setup.md</path>
        <title>Story 1.2: PostgreSQL + pgvector Setup</title>
        <section>Dev Notes - Learnings</section>
        <snippet>Type Hints Requirement: Use `from psycopg2.extensions import connection` für type hints. Do NOT use `-> psycopg2.connect` (function, not type) - causes mypy failure. Environment: .env.development is in PROJECT ROOT. Code Quality: Black + Ruff + mypy --strict, Type hints REQUIRED.</snippet>
      </doc>
      <doc>
        <path>docs/POSTGRESQL_SETUP.md</path>
        <title>PostgreSQL Setup Documentation</title>
        <section>Database Configuration</section>
        <snippet>PostgreSQL setup documentation for connection configuration and database schema.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>mcp_server/__init__.py</path>
        <kind>package</kind>
        <symbol>mcp_server</symbol>
        <lines>all</lines>
        <reason>Main package - bereits vorhanden aus Story 1.1</reason>
      </artifact>
      <artifact>
        <path>mcp_server/db/__init__.py</path>
        <kind>package</kind>
        <symbol>mcp_server.db</symbol>
        <lines>all</lines>
        <reason>DB package - bereits vorhanden aus Story 1.1</reason>
      </artifact>
      <artifact>
        <path>mcp_server/db/migrations/001_initial_schema.sql</path>
        <kind>migration</kind>
        <symbol>initial_schema</symbol>
        <lines>1-50</lines>
        <reason>Database schema mit 6 Tabellen (l0_raw, l2_insights, working_memory, episode_memory, stale_memory, ground_truth) - bereits vorhanden aus Story 1.2</reason>
      </artifact>
      <artifact>
        <path>mcp_server/tools/__init__.py</path>
        <kind>package</kind>
        <symbol>mcp_server.tools</symbol>
        <lines>all</lines>
        <reason>Tool package - bereits vorhanden, wird für Tool Registry erweitert in dieser Story</reason>
      </artifact>
      <artifact>
        <path>mcp_server/resources/__init__.py</path>
        <kind>package</kind>
        <symbol>mcp_server.resources</symbol>
        <lines>all</lines>
        <reason>Resource package - bereits vorhanden, wird für Resource Registry erweitert in dieser Story</reason>
      </artifact>
      <artifact>
        <path>tests/test_database.py</path>
        <kind>test</kind>
        <symbol>test_database</symbol>
        <lines>all</lines>
        <reason>Database test patterns established aus Story 1.2 - kann als Referenz für Integration Tests verwendet werden</reason>
      </artifact>
      <artifact>
        <path>pyproject.toml</path>
        <kind>config</kind>
        <symbol>poetry_config</symbol>
        <lines>1-93</lines>
        <reason>Dependencies: mcp, psycopg2-binary, pgvector bereits installiert. Black, Ruff, mypy konfiguriert. Type hints: strict mode.</reason>
      </artifact>
      <artifact>
        <path>.env.development</path>
        <kind>config</kind>
        <symbol>env_config</symbol>
        <lines>all</lines>
        <reason>Environment Variables für PostgreSQL Connection - muss erweitert werden mit LOG_LEVEL in dieser Story</reason>
      </artifact>
      <artifact>
        <path>mcp_server/__main__.py</path>
        <kind>entry_point</kind>
        <symbol>__main__</symbol>
        <lines>NEW</lines>
        <reason>Entry Point für `python -m mcp_server` - erstellt in Story 1.3. WICHTIG: __main__.py (mit Underscores), NICHT main.py!</reason>
      </artifact>
      <artifact>
        <path>mcp_server/db/connection.py</path>
        <kind>module</kind>
        <symbol>connection_pool</symbol>
        <lines>NEW</lines>
        <reason>Connection Pool Modul mit get_connection() Context Manager - erstellt in Story 1.3. Type Hint: Iterator[connection] aus psycopg2.extensions.</reason>
      </artifact>
      <artifact>
        <path>tests/test_mcp_server.py</path>
        <kind>test</kind>
        <symbol>test_mcp_server</symbol>
        <lines>NEW</lines>
        <reason>Integration Tests für MCP Server - erstellt in Story 1.3. subprocess.Popen-based testing mit stdin/stdout pipes.</reason>
      </artifact>
    </code>
    <dependencies>
      <python>
        <package name="mcp" version="^1.0.0">Python MCP SDK für Server Implementation</package>
        <package name="psycopg2-binary" version="^2.9.0">PostgreSQL adapter</package>
        <package name="pgvector" version="^0.2.0">pgvector Python client</package>
        <package name="python-dotenv" version="^1.0.0">Environment variable management</package>
        <package name="numpy" version="^1.24.0">Array operations (für Embeddings)</package>
        <package name="openai" version="^1.0.0">OpenAI API client (für später)</package>
        <package name="anthropic" version="^0.25.0">Anthropic API client (für später)</package>
      </python>
      <dev_dependencies>
        <package name="jsonschema" version="^4.20.0">JSON Schema validation für Tool-Parameter (fallback falls MCP SDK keine Validation hat)</package>
        <package name="black" version="^23.0.0">Code formatting (line-length=88)</package>
        <package name="ruff" version="^0.1.0">Linting</package>
        <package name="mypy" version="^1.7.0">Type checking (strict mode)</package>
        <package name="pytest" version="^7.4.0">Testing framework</package>
        <package name="pytest-cov" version="^4.1.0">Test coverage</package>
        <package name="pre-commit" version="^3.5.0">Pre-commit hooks</package>
      </dev_dependencies>
    </dependencies>
  </artifacts>

  <constraints>
    - MCP Protocol Requirements:
      * Transport: stdio (Standard für lokale MCP Server)
      * Handshake: Server MUSS protocol version und capabilities senden
      * Tool Discovery: list_tools() MUSS alle registrierten Tools zurückgeben
      * Resource Discovery: list_resources() MUSS alle URIs zurückgeben
      * Error Handling: MCP Error Responses gemäß Spec (error code + message)

    - Database Connection Pool:
      * psycopg2.pool.SimpleConnectionPool (thread-safe)
      * min_conn=1 (minimum connections)
      * max_conn=10 (maximum connections)
      * Connection reuse für Performance
      * Health Check vor Verwendung

    - Type Hints REQUIRED (mypy --strict):
      * CRITICAL: Use `from psycopg2.extensions import connection` für type hints
      * Do NOT use `-> psycopg2.connect` (function, not type) - verursacht mypy failure
      * Alle Funktionen müssen Type Hints haben
      * async def Funktionen für MCP Server (asyncio)

    - Logging Strategy:
      * Structured Logging mit JSON (für Production-Auswertung)
      * Log Levels: DEBUG (Development), INFO (Production)
      * Log Destination: stderr (nicht stdout - stdout ist für MCP protocol!)
      * Log Format: JSON mit fields: timestamp, level, message, module

    - Code Quality Standards:
      * Black (line-length=88) + Ruff für linting
      * Pre-commit hooks active
      * Error handling mit try/except/finally
      * Cleanup on error (WRITE-Tests pattern aus Story 1.2)

    - Entry Point Pattern:
      * Claude Code MCP Config nutzt: "args": ["-m", "mcp_server"]
      * Das erfordert __main__.py (nicht main.py)
      * Konsistent mit Python Module Execution Pattern

    - Testing Strategy:
      * subprocess.Popen für Integration Tests (stdio transport testing)
      * JSON-RPC 2.0 format für MCP requests
      * Helper functions: write_mcp_request(), read_mcp_response()

    - Environment Configuration:
      * .env.development is in PROJECT ROOT (not in config/)
      * Use python-dotenv mit load_dotenv('.env.development')
      * File permissions: chmod 600
  </constraints>
  <interfaces>
    - MCP Server Core:
      * Tool Handler Signature: async def tool_handler(name: str, arguments: Dict[str, Any]) -> Dict[str, Any]
      * Resource Handler Signature: async def resource_handler(uri: str) -> Dict[str, Any]

    - Connection Pool Context Manager:
      * Signature: @contextmanager def get_connection() -> Iterator[connection]
      * Usage: with get_connection() as conn: ...
      * Returns: psycopg2.extensions.connection object

    - Tool Registration:
      * @server.list_tools() -> list[Tool]
      * Tool Schema: {"name": str, "description": str, "parameters": dict}

    - Resource Registration:
      * @server.list_resources() -> list[Resource]
      * Resource Schema: {"uri": str, "name": str, "description": str}
      * URI Pattern: memory://resource-name?param1=value1

    - Signal Handling:
      * signal.signal(signal.SIGTERM, signal_handler)
      * signal.signal(signal.SIGINT, signal_handler)
      * Graceful shutdown: close DB connections, exit code 0

    - JSON Schema Validation:
      * from jsonschema import validate, ValidationError
      * Tool parameter validation vor execution

    - Logging Configuration:
      * class JSONFormatter(logging.Formatter)
      * Log Destination: sys.stderr (nicht stdout!)
      * Log Format: JSON mit {timestamp, level, message, module}
      * Level: DEBUG (development), INFO (production) from .env.development

    - Resource URI Parsing:
      * def parse_resource_uri(uri: str) -> Tuple[str, Dict[str, List[str]]]
      * Example: "memory://l2-insights?query=test&top_k=5" → ("memory://l2-insights", {"query": ["test"], "top_k": ["5"]})
      * Library: urllib.parse (Python stdlib)
  </interfaces>
  <tests>
    <standards>
      Testing Framework: pytest mit subprocess-based testing für MCP Server Integration Tests.

      Unit Tests: Mock DB connections (psycopg2), Mock API responses.

      Integration Tests:
      - Start MCP Server as subprocess: subprocess.Popen mit stdin/stdout/stderr pipes
      - Write MCP requests to stdin (JSON-RPC 2.0 format)
      - Read MCP responses from stdout
      - Validate protocol compliance

      Helper Functions Pattern:
      - write_mcp_request(proc, method, params): Write JSON-RPC request to stdin
      - read_mcp_response(proc): Read JSON-RPC response from stdout

      Code Quality: All tests must pass Black, Ruff, mypy --strict checks.

      Test Pattern aus Story 1.2: WRITE-Tests with cleanup on error (try/finally pattern).
    </standards>
    <locations>
      tests/test_mcp_server.py - Integration Tests für MCP Server
      tests/test_database.py - Existing database tests (Referenz)
      mcp_server/db/connection.py - Connection Pool (Unit Tests)
      mcp_server/tools/__init__.py - Tool Registry (Unit Tests)
      mcp_server/resources/__init__.py - Resource Registry (Unit Tests)
    </locations>
    <ideas>
      AC-1: MCP Server Start und Erreichbarkeit
      - Test 1: Server Start (subprocess, check stderr für "Server started")
      - Test 2: MCP Handshake via stdin/stdout pipes (JSON-RPC 2.0)
      - Test 3: Server loggt eingehende Requests (Structured JSON Logging)

      AC-2: Tool Registration Framework
      - Test 4: list_tools() via MCP Protocol → parse stdout, verify 7 tools
      - Test 5: call_tool("ping") via stdin → "pong" auf stdout
      - Test 6: call_tool mit invalid parameters → Error Response

      AC-3: Resource Registration Framework
      - Test 7: list_resources() via MCP Protocol → parse stdout, verify 5 resources
      - Test 8: read_resource("memory://status") → DB Status

      AC-4: Database Connection Pool
      - Test 9: get_connection() Context Manager → verify connection returned
      - Test 10: Connection Health Check → verify SELECT 1 test
      - Test 11: close_all_connections() → verify graceful shutdown
      - Test 12: Pool exhausted scenario → verify PoolError raised

      AC-5: Testing und Validation
      - Test 13: Integration-Test: Server Start → Handshake → Tool Call → Resource Read → Shutdown
      - Test 14: SIGTERM → Graceful Shutdown (exit code 0, connections closed)
    </ideas>
  </tests>
</story-context>
