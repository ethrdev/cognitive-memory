<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>1</storyId>
    <title>Claude Code MCP Client Setup &amp; Integration Testing</title>
    <status>ready-for-dev</status>
    <generatedAt>2025-11-14</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>bmad-docs/stories/2-1-claude-code-mcp-client-setup-integration-testing.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>Entwickler</asA>
    <iWant>Claude Code als MCP Client konfigurieren und Verbindung zum MCP Server testen</iWant>
    <soThat>Claude Code alle MCP Tools und Resources nutzen kann</soThat>
    <tasks>
- [ ] MCP Server Configuration in Claude Code (AC: 1)
  - [ ] Erstelle oder aktualisiere `~/.config/claude-code/mcp-settings.json`
  - [ ] Füge Cognitive Memory Server Config hinzu (command, args, env vars)
  - [ ] Verifiziere MCP Server ist lokal erreichbar (stdio transport)
  - [ ] Teste Handshake zwischen Claude Code und MCP Server

- [ ] Tool Discovery Test (AC: 1, 2)
  - [ ] Öffne Claude Code Tool-Liste Interface
  - [ ] Verifiziere alle 7 Tools werden angezeigt
  - [ ] Verifiziere Tool-Schemas sind korrekt (Parameter, Descriptions)
  - [ ] Führe `ping` Tool-Call aus → Erwarte "pong" Response

- [ ] Individual Tool Integration Tests (AC: 2)
  - [ ] Test `store_raw_dialogue`: Speichere Test-Dialog, verifiziere in PostgreSQL
  - [ ] Test `compress_to_l2_insight`: Speichere Dummy L2 Insight mit Embedding
  - [ ] Test `hybrid_search`: Query mit existierenden L2 Insights, verifiziere Top-K Results
  - [ ] Test `update_working_memory`: Füge Item hinzu, verifiziere LRU Eviction funktioniert
  - [ ] Test `store_episode`: Speichere Test-Episode, verifiziere Embedding gespeichert
  - [ ] Test `get_golden_test_results`: Erwarte Dummy Response (Tool existiert als Stub, vollständige Implementierung folgt in Epic 3)
  - [ ] Test `store_dual_judge_scores`: Verifiziere Tool funktioniert (bereits aus Epic 1)

- [ ] Resource Discovery &amp; Read Tests (AC: 3)
  - [ ] Öffne Claude Code Resource-Liste Interface
  - [ ] Verifiziere alle 5 Resources werden angezeigt
  - [ ] Test `memory://l2-insights?query=test&amp;top_k=5`: Verifiziere JSON Response mit L2 Insights
  - [ ] Test `memory://working-memory`: Verifiziere aktuelle Working Memory Items zurückgegeben
  - [ ] Test `memory://episode-memory?query=test&amp;min_similarity=0.7`: Verifiziere Episode Retrieval
  - [ ] Test `memory://l0-raw?session_id={test-session}`: Verifiziere Raw Dialogue Transkripte
  - [ ] Test `memory://stale-memory`: Verifiziere archivierte Items zurückgegeben

- [ ] Integration Testing &amp; Documentation (AC: alle)
  - [ ] Führe End-to-End Test durch: Query → Tool Call → Response
  - [ ] Teste Error Handling: Invalid Parameters, Missing Resources, API Failures
  - [ ] Dokumentiere MCP Settings JSON Structure in `/docs/mcp-configuration.md`
  - [ ] Dokumentiere Troubleshooting-Schritte (häufige Connection-Issues)
</tasks>
  </story>

  <acceptanceCriteria>
**Given** der MCP Server läuft lokal (Epic 1 abgeschlossen)
**When** ich Claude Code MCP Settings konfiguriere
**Then** ist die Integration funktional:

1. **MCP Server Registration &amp; Discovery:**
   - MCP Server in `~/.config/claude-code/mcp-settings.json` registriert
   - Claude Code zeigt verfügbare Tools (7 Tools) in Tool-Liste
   - Claude Code zeigt verfügbare Resources (5 Resources)
   - Test-Tool-Call erfolgreich: `ping` → "pong" Response

2. **All 7 MCP Tools sind aufrufbar:**
   - `store_raw_dialogue` - L0 Storage Test
   - `compress_to_l2_insight` - L2 Storage Test (mit Dummy Embedding)
   - `hybrid_search` - Retrieval Test (mit vorhandenen L2 Insights)
   - `update_working_memory` - Working Memory Test
   - `store_episode` - Episode Storage Test
   - `get_golden_test_results` - Stub implementation mit Dummy Response (vollständige Implementierung in Epic 3)
   - `store_dual_judge_scores` - Bereits funktional aus Epic 1

3. **All 5 MCP Resources sind lesbar:**
   - `memory://l2-insights?query=test&amp;top_k=5`
   - `memory://working-memory`
   - `memory://episode-memory?query=test&amp;min_similarity=0.7`
   - `memory://l0-raw?session_id={test-session}`
   - `memory://stale-memory`
</acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>bmad-docs/tech-spec-epic-2.md</path>
        <title>Technical Specification - Epic 2</title>
        <section>Claude Code ↔ MCP Server Integration (Lines 299-309)</section>
        <snippet>MCP Settings configuration in JSON format: server command is "python" with args pointing to mcp_server/main.py, environment variables include ANTHROPIC_API_KEY and OPENAI_API_KEY. Transport uses stdio (standard for local MCP servers).</snippet>
      </doc>
      <doc>
        <path>bmad-docs/tech-spec-epic-2.md</path>
        <title>Technical Specification - Epic 2</title>
        <section>Story 2.1 Acceptance Criteria (Lines 387-391)</section>
        <snippet>Authoritative ACs: Given MCP Server running locally, when Claude Code MCP Settings configured, then all 7 MCP Tools (ping, store_raw_dialogue, compress_to_l2_insight, hybrid_search, update_working_memory, store_episode, store_dual_judge_scores) and 5 Resources (memory://l2-insights, memory://working-memory, memory://episode-memory, memory://l0-raw, memory://stale-memory) are callable.</snippet>
      </doc>
      <doc>
        <path>bmad-docs/architecture.md</path>
        <title>Cognitive Memory System Architecture</title>
        <section>High-Level Architecture (Lines 44-82)</section>
        <snippet>System architecture shows Claude Code (Sonnet 4.5) as MCP Client connecting to MCP Server (Python, local) via stdio transport. MCP Server exposes 7 Tools and 5 Resources, backed by PostgreSQL + pgvector. External APIs: OpenAI Embeddings, Anthropic Haiku, GPT-4o.</snippet>
      </doc>
      <doc>
        <path>bmad-docs/architecture.md</path>
        <title>Cognitive Memory System Architecture</title>
        <section>Technology Decisions (Lines 18-37)</section>
        <snippet>Key decisions: MCP Server uses Python MCP SDK (latest), stdio transport. Claude Code uses Sonnet 4.5 in MAX subscription for bulk ops (€0/mo). PostgreSQL 15+ with pgvector for vector search.</snippet>
      </doc>
      <doc>
        <path>bmad-docs/epics.md</path>
        <title>Epic Breakdown</title>
        <section>Story 2.1: Claude Code MCP Client Setup (Lines 517-556)</section>
        <snippet>Story defines MCP Client setup and integration testing. Prerequisites: Epic 1 completed (all Tools/Resources implemented). Testing strategy: Manual testing in Claude Code interface, no automated tests required. MCP Settings location: ~/.config/claude-code/mcp-settings.json (JSON format with server path, args, env vars).</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>mcp_server/__main__.py</path>
        <kind>server-entrypoint</kind>
        <symbol>main()</symbol>
        <lines>75-140</lines>
        <reason>MCP Server Entry Point - must be referenced in mcp-settings.json as "python -m mcp_server". Server initializes 7 tools and 5 resources, uses stdio transport for Claude Code communication.</reason>
      </artifact>
      <artifact>
        <path>mcp_server/tools/__init__.py</path>
        <kind>tools-registry</kind>
        <symbol>register_tools()</symbol>
        <lines>1287-1539</lines>
        <reason>All 7 MCP Tools registered: ping, store_raw_dialogue, compress_to_l2_insight, hybrid_search, update_working_memory, store_episode, get_golden_test_results (stub), store_dual_judge_scores. Each has JSON schema for validation and async handler.</reason>
      </artifact>
      <artifact>
        <path>mcp_server/tools/__init__.py</path>
        <kind>tool-implementation</kind>
        <symbol>handle_ping()</symbol>
        <lines>1269-1284</lines>
        <reason>Ping tool - simplest connectivity test. Returns "pong" with timestamp. Critical first test in integration workflow.</reason>
      </artifact>
      <artifact>
        <path>mcp_server/resources/__init__.py</path>
        <kind>resources-registry</kind>
        <symbol>register_resources()</symbol>
        <lines>564-645</lines>
        <reason>All 5 MCP Resources registered: memory://l2-insights, memory://working-memory, memory://episode-memory, memory://l0-raw, memory://stale-memory. Each resource has URI pattern and async read handler.</reason>
      </artifact>
      <artifact>
        <path>mcp_server/tools/__init__.py</path>
        <kind>tool-stub</kind>
        <symbol>get_golden_test_results (stub)</symbol>
        <lines>N/A</lines>
        <reason>Golden Test Results tool stub - returns dummy response in Story 2.1. Full implementation scheduled for Epic 3 (Story 3.2). Tool must be registered and callable for Story 2.1 integration testing, but actual golden test set creation happens later.</reason>
      </artifact>
      <artifact>
        <path>mcp_server/db/connection.py</path>
        <kind>database-connection</kind>
        <symbol>get_connection()</symbol>
        <lines>N/A</lines>
        <reason>Database connection pool context manager - provides DictCursor connections. Used by all tools and resources for PostgreSQL access. Pattern established in Epic 1.</reason>
      </artifact>
    </code>
    <dependencies>
      <python>
        <runtime>Python 3.11+</runtime>
        <package-manager>Poetry (pyproject.toml) or pip (requirements.txt)</package-manager>
        <core-dependencies>
          <dependency name="mcp" version="^1.0.0" purpose="MCP Server SDK - stdio transport, tool/resource registration"/>
          <dependency name="psycopg2-binary" version="^2.9.0" purpose="PostgreSQL adapter with DictCursor support"/>
          <dependency name="pgvector" version="^0.2.0" purpose="PostgreSQL vector extension for semantic search"/>
          <dependency name="openai" version="^1.0.0" purpose="OpenAI API client for text-embedding-3-small (1536-dim embeddings)"/>
          <dependency name="anthropic" version="^0.25.0" purpose="Anthropic API client for Claude Haiku (evaluation, reflexion)"/>
          <dependency name="python-dotenv" version="^1.0.0" purpose="Environment variable loading from .env files"/>
          <dependency name="numpy" version="^1.24.0" purpose="Numerical operations (used by scipy, scikit-learn)"/>
          <dependency name="streamlit" version="^1.28.0" purpose="Ground Truth Collection UI (Epic 1.10)"/>
          <dependency name="scipy" version="^1.11.0" purpose="Scientific computing (IRR validation, Cohen's Kappa)"/>
          <dependency name="scikit-learn" version="^1.3.0" purpose="Machine learning utilities (Epic 1.12 IRR validation)"/>
        </core-dependencies>
        <dev-dependencies>
          <dependency name="black" version="^23.0.0" purpose="Code formatter"/>
          <dependency name="ruff" version="^0.1.0" purpose="Linter (pycodestyle, pyflakes, isort)"/>
          <dependency name="mypy" version="^1.7.0" purpose="Type checker"/>
          <dependency name="pytest" version="^7.4.0" purpose="Testing framework"/>
          <dependency name="pytest-asyncio" version="^0.21.0" purpose="Async test support"/>
          <dependency name="pytest-cov" version="^4.1.0" purpose="Test coverage"/>
        </dev-dependencies>
      </python>
      <database>
        <dependency name="PostgreSQL" version="15+" purpose="Primary database with pgvector extension for vector search"/>
        <dependency name="pgvector" version="latest" purpose="PostgreSQL extension for cosine distance search (<=> operator)"/>
      </database>
      <external-apis>
        <api name="OpenAI Embeddings API" model="text-embedding-3-small" purpose="Generate 1536-dim embeddings for L2 insights and episodes"/>
        <api name="Anthropic Haiku API" model="claude-3-5-haiku-20241022" purpose="Self-evaluation and reflexion (Epic 2)"/>
        <api name="OpenAI GPT-4o API" model="gpt-4o" purpose="Dual Judge evaluation (Epic 1)"/>
      </external-apis>
      <environment-variables>
        <var name="ANTHROPIC_API_KEY" required="true" purpose="Anthropic API authentication"/>
        <var name="OPENAI_API_KEY" required="true" purpose="OpenAI API authentication"/>
        <var name="DATABASE_URL" required="false" purpose="PostgreSQL connection string (optional, defaults to localhost)"/>
        <var name="LOG_LEVEL" required="false" purpose="Logging level (DEBUG, INFO, WARNING, ERROR) - defaults to INFO"/>
      </environment-variables>
    </dependencies>
  </artifacts>

  <constraints>
- MCP Transport: stdio transport ONLY (no HTTP/WebSocket). Claude Code communicates via stdin/stdout pipes.
- MCP Settings Location: OS-specific paths - Linux/macOS: ~/.config/claude-code/mcp-settings.json, Windows: %APPDATA%/Claude/mcp-settings.json (verify actual path in Claude Code documentation before implementation)
- Command Format: Must use absolute paths in args array (not relative paths). Prefer ["-m", "mcp_server"] module syntax over direct __main__.py path.
- Python Interpreter: Use "python" as command. If using virtual environment, ensure venv is activated in shell before starting Claude Code, OR specify absolute path to venv python in command field.
- Environment Variables: API keys referenced as ${ANTHROPIC_API_KEY} and ${OPENAI_API_KEY} (inherited from shell environment)
- Testing Strategy: Manual integration testing ONLY. No automated tests required for Story 2.1.
- Test Sequence: Test tools/resources individually (sequential, not parallel) to isolate potential failures
- Error Handling: All tools return structured error responses (no crashes). Graceful degradation required.
- Latency Budget: Tool calls must complete within 5s (excluding API retry delays)
  </constraints>
  <interfaces>
    <interface>
      <name>MCP Protocol Handshake</name>
      <kind>protocol</kind>
      <signature>Claude Code → Initialize Request → MCP Server responds with Tool/Resource schemas</signature>
      <path>mcp_server/__main__.py:106-114</path>
      <description>MCP Protocol flow: 1) Claude Code starts subprocess, 2) Handshake via Initialize, 3) Server returns tool/resource schemas, 4) Claude Code caches schemas for session. All communication via stdin/stdout JSON-RPC.</description>
    </interface>
    <interface>
      <name>MCP Settings JSON Format</name>
      <kind>configuration</kind>
      <signature>{ "mcpServers": { "cognitive-memory": { "command": str, "args": [str], "env": {str: str} } } }</signature>
      <path>~/.config/claude-code/mcp-settings.json</path>
      <description>Required structure for Claude Code MCP configuration. Server name "cognitive-memory" is user-defined. Command must be "python", args array should contain either ["-m", "mcp_server"] for module syntax OR ["/absolute/path/to/mcp_server/__main__.py"] for direct path.</description>
    </interface>
    <interface>
      <name>Tool Call Interface</name>
      <kind>mcp-tool</kind>
      <signature>async def call_tool_handler(name: str, arguments: dict[str, Any]) -> dict[str, Any]</signature>
      <path>mcp_server/tools/__init__.py:1504-1536</path>
      <description>All tool calls use this interface. Name identifies tool, arguments validated against JSON schema. Returns success dict or error dict with "error", "details", "tool" keys.</description>
    </interface>
    <interface>
      <name>Resource Read Interface</name>
      <kind>mcp-resource</kind>
      <signature>async def read_resource_handler(uri: str) -> dict[str, Any]</signature>
      <path>mcp_server/resources/__init__.py:621-642</path>
      <description>All resource reads use URI-based requests. URI includes query parameters (e.g., memory://l2-insights?query=test&amp;top_k=5). Returns JSON array or error dict.</description>
    </interface>
  </interfaces>
  <tests>
    <standards>
Story 2.1 uses MANUAL INTEGRATION TESTING exclusively - no automated tests required for this story. Testing is performed directly in Claude Code interface to validate MCP Client-Server communication.

**Testing Framework (Epic 1 - Reference Only):**
- pytest (^7.4.0) with pytest-asyncio for async test support
- Subprocess-based MCP Server testing (see tests/test_mcp_server.py)
- Mock-based unit tests for database-independent logic
- Integration tests with PostgreSQL test database
- Pattern: Comprehensive edge case coverage (empty data, None values, invalid inputs)

**Story 2.1 Manual Testing Approach:**
- Test Environment: Claude Code interface (not automated test suite)
- Test Execution: Sequential testing (not parallel) to isolate failures
- Verification Method: Visual inspection + PostgreSQL query verification
- Error Handling: Expect structured error responses (JSON with "error", "details", "tool" keys)
- Success Criteria: All 7 tools functional, all 5 resources return valid JSON, latency &lt;5s per call

**Manual Test Phases (from Dev Notes):**
1. **Phase 1: Connection &amp; Discovery** - Restart Claude Code, verify 7 tools + 5 resources shown, run ping tool
2. **Phase 2: Tool Functionality Tests** - Run tools sequentially, verify PostgreSQL entries after each call
3. **Phase 3: Resource Read Tests** - Query resources with various parameters, verify JSON format
4. **Phase 4: Error Handling** - Test invalid parameters, non-existent URIs, API failures (graceful degradation)
    </standards>
    <locations>
- tests/ - Automated test suite from Epic 1 (pytest-based, NOT used for Story 2.1)
- tests/test_mcp_server.py - Subprocess-based MCP integration tests (reference pattern)
- tests/test_*.py - Individual tool/resource tests (hybrid_search, dual_judge, etc.)
- Story 2.1: NO test files created (manual testing only)
    </locations>
    <ideas>
**AC 1: MCP Server Registration &amp; Discovery**
- Idea 1.1: After updating mcp-settings.json, restart Claude Code and verify MCP Server appears in available servers list
- Idea 1.2: Open Claude Code Tool-Liste and count tools (expect exactly 7: ping, store_raw_dialogue, compress_to_l2_insight, hybrid_search, update_working_memory, store_episode, store_dual_judge_scores)
- Idea 1.3: Open Claude Code Resource-Liste and count resources (expect exactly 5: memory://l2-insights, memory://working-memory, memory://episode-memory, memory://l0-raw, memory://stale-memory)
- Idea 1.4: Execute ping tool call in Claude Code, verify response contains "pong" and timestamp

**AC 2: All 7 MCP Tools are callable**
- Idea 2.1: Test store_raw_dialogue with test session_id, verify INSERT into l0_raw table via psql query
- Idea 2.2: Test compress_to_l2_insight with dummy content, verify L2 insight stored with 1536-dim embedding
- Idea 2.3: Test hybrid_search with existing L2 insights, verify Top-K results returned with RRF scores
- Idea 2.4: Test update_working_memory with importance=0.5, verify LRU eviction if capacity exceeded
- Idea 2.5: Test store_episode with query/reward/reflection, verify embedding stored in episode_memory table
- Idea 2.6: Test get_golden_test_results (stub), expect dummy response (full implementation in Epic 3)
- Idea 2.7: Test store_dual_judge_scores (Epic 1 tool), verify still functional after Story 2.1 changes

**AC 3: All 5 MCP Resources are readable**
- Idea 3.1: Read memory://l2-insights?query=test&amp;top_k=5, verify JSON array with id/content/score/source_ids
- Idea 3.2: Read memory://working-memory, verify JSON array sorted by last_accessed DESC
- Idea 3.3: Read memory://episode-memory?query=test&amp;min_similarity=0.7, verify similarity filtering works
- Idea 3.4: Read memory://l0-raw?session_id={test-session}, verify raw dialogue transcripts returned
- Idea 3.5: Read memory://stale-memory, verify archived items returned with importance/reason fields

**Error Handling &amp; Edge Cases**
- Idea 4.1: Call tool with invalid parameters (missing required field), expect error response with "error" key
- Idea 4.2: Read non-existent resource URI (memory://invalid), expect error response (not crash)
- Idea 4.3: Temporarily remove OPENAI_API_KEY from environment, call compress_to_l2_insight, expect graceful API error
- Idea 4.4: Call hybrid_search with empty query_text, expect parameter validation error
- Idea 4.5: Measure latency for each tool call (should be &lt;5s excluding API retry delays)

**Documentation Validation**
- Idea 5.1: Create /docs/mcp-configuration.md documenting mcp-settings.json structure
- Idea 5.2: Document troubleshooting steps for common issues (MCP Server not found, connection refused, tool-liste leer, API key errors)
    </ideas>
  </tests>
</story-context>
