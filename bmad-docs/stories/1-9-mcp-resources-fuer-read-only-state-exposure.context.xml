<story-context id="bmad/bmm/workflows/4-implementation/story-context/1-9-mcp-resources-fuer-read-only-state-exposure" v="1.0">
  <metadata>
    <epicId>1</epicId>
    <storyId>9</storyId>
    <title>MCP Resources für Read-Only State Exposure</title>
    <status>drafted</status>
    <generatedAt>2025-11-12</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>bmad-docs/stories/1-9-mcp-resources-fuer-read-only-state-exposure.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>Als Claude Code,</asA>
    <iWant>möchte ich MCP Resources nutzen um Memory-State zu lesen,</iWant>
    <soThat>sodass ich Kontext vor Aktionen laden kann (z.B. Episode Memory vor Answer Generation).</soThat>
    <tasks>- [ ] MCP Resource Framework Implementation (AC: alle)
  - [ ] Implement Resource Registry System in MCP Server
  - [ ] Define Resource URI Schema (memory:// prefix)
  - [ ] Implement URI parsing with query parameters
  - [ ] Implement JSON response formatting (MCP Standard)
  - [ ] Implement error handling (400 for invalid params, empty array [] for no results, 404 for invalid URIs)

- [ ] Resource 1: memory://l2-insights (AC: 1)
  - [ ] Parse query parameters: query (required), top_k (optional, default 5)
  - [ ] Initialize OpenAI client (load OPENAI_API_KEY from environment)
  - [ ] Embed query text using OpenAI API: `await get_embedding_with_retry(client, query)`
  - [ ] Register pgvector type: `register_vector(conn)` (required before semantic search)
  - [ ] Execute semantic search on l2_insights table
  - [ ] Return Top-K results: [{id, content, score, source_ids}]
  - [ ] Handle errors: empty query → 400, no results → empty array []

- [ ] Resource 2: memory://working-memory (AC: 2)
  - [ ] SELECT all items from working_memory table
  - [ ] Sort by last_accessed DESC (neueste zuerst)
  - [ ] Return: [{id, content, importance, last_accessed, created_at}]
  - [ ] Handle empty state: return empty array [] (not 404)

- [ ] Resource 3: memory://episode-memory (AC: 3)
  - [ ] Parse query parameters: query (required), min_similarity (optional, default 0.70)
  - [ ] Initialize OpenAI client (load OPENAI_API_KEY from environment)
  - [ ] Embed query text using OpenAI API: `await get_embedding_with_retry(client, query)`
  - [ ] Register pgvector type: `register_vector(conn)` (required before semantic search)
  - [ ] Execute semantic search on episode_memory table
  - [ ] Filter by cosine similarity >= min_similarity
  - [ ] Limit to Top-3 episodes (FR009 requirement)
  - [ ] Return: [{id, query, reward, reflection, similarity}]
  - [ ] Handle errors: empty query → 400, no results above threshold → empty array []

- [ ] Resource 4: memory://l0-raw (AC: 4)
  - [ ] Parse query parameters: session_id (optional), date_range (optional), limit (optional, default 100)
  - [ ] SELECT from l0_raw with filters:
    - [ ] If session_id provided: WHERE session_id = {id}
    - [ ] If date_range provided: WHERE timestamp BETWEEN start AND end
    - [ ] Apply limit: LIMIT {limit} (default 100, max 1000)
    - [ ] Sort by timestamp DESC (most recent first)
  - [ ] Return: [{id, session_id, timestamp, speaker, content, metadata}]
  - [ ] Handle errors: invalid date format → 400, invalid limit → 400, no results → empty array []

- [ ] Resource 5: memory://stale-memory (AC: 5)
  - [ ] Parse query parameters: importance_min (optional)
  - [ ] SELECT from stale_memory with optional filter:
    - [ ] If importance_min provided: WHERE importance >= {t}
    - [ ] Else: return all stale memory items
  - [ ] Return: [{id, original_content, archived_at, importance, reason}]
  - [ ] Handle empty archive: return empty array [] (not 404)

- [ ] Integration Tests für MCP Resources (AC: alle)
  - [ ] Test-File: `tests/test_resources.py` erstellen
  - [ ] Test 1: memory://l2-insights - verify query embedding + semantic search
  - [ ] Test 2: memory://working-memory - verify sorted by last_accessed DESC
  - [ ] Test 3: memory://episode-memory - verify min_similarity filtering + Top-3 limit
  - [ ] Test 4: memory://l0-raw - verify session_id filter + date_range parsing
  - [ ] Test 5: memory://stale-memory - verify importance_min filter
  - [ ] Test 6: Error handling - invalid parameters → 400, no results → empty array []
  - [ ] Test 7: URI parsing - verify query parameter extraction
  - [ ] Test 8: Read-Only verification - verify resources do NOT mutate database state
    - [ ] Count rows before resource call
    - [ ] Call resource
    - [ ] Count rows after resource call
    - [ ] Assert: row count unchanged for ALL tables
  - [ ] Test Cleanup: DELETE test data in teardown

- [ ] End-to-End MCP Resource Access Test (AC: alle)
  - [ ] Update `tests/test_mcp_server.py`
  - [ ] Test: read_resource("memory://l2-insights?query=test&top_k=5")
  - [ ] Test: read_resource("memory://working-memory")
  - [ ] Test: read_resource("memory://episode-memory?query=test&min_similarity=0.7")
  - [ ] Test: read_resource("memory://l0-raw?session_id={test-uuid}")
  - [ ] Test: read_resource("memory://stale-memory?importance_min=0.8")
  - [ ] Verify: Response format matches specification
  - [ ] Cleanup: DELETE test data after test

- [ ] Documentation Updates (AC: alle)
  - [ ] README.md: Add MCP Resources section with all 5 URIs
  - [ ] README.md: Document query parameters for each resource
  - [ ] README.md: Provide usage examples from Claude Code
  - [ ] API Reference: Document response formats and error codes</tasks>
  </story>

  <acceptanceCriteria>**Given** der MCP Server läuft und Daten existieren
**When** Claude Code MCP Resources abruft
**Then** sind folgende Resources verfügbar:

1. **`memory://l2-insights?query={q}&top_k={k}`**
   - Gibt Top-K L2 Insights für Query zurück
   - Response: JSON mit [{ id, content, score, source_ids }]

2. **`memory://working-memory`**
   - Gibt alle aktuellen Working Memory Items zurück
   - Sortiert nach last_accessed (neueste zuerst)

3. **`memory://episode-memory?query={q}&min_similarity={t}`**
   - Gibt ähnliche vergangene Episodes zurück
   - Default: min_similarity=0.70, top_k=3 (FR009)
   - Response: [{ id, query, reward, reflection, similarity }]

4. **`memory://l0-raw?session_id={id}&date_range={r}`**
   - Gibt Raw Dialogtranskripte für Session/Zeitraum zurück
   - Optional: date_range im Format "2024-01-01:2024-01-31"

5. **`memory://stale-memory?importance_min={t}`**
   - Gibt archivierte Items zurück (optional gefiltert nach Importance)

**And** alle Resources sind Read-Only:
- Keine Mutations erlaubt
- URI-Schema: `memory://` Prefix
- Query-Parameter aus URI geparst
- Response-Format: JSON (MCP Standard)
- Error Handling:
  - **400 Bad Request** wenn Parameter invalid sind (z.B., empty query, invalid date format, invalid limit)
  - **Empty array `[]`** wenn Query keine Ergebnisse liefert (NOT 404)
  - **404 Not Found** nur wenn Resource URI selbst invalid ist (z.B., `memory://invalid-resource`)</acceptanceCriteria>

  <artifacts>
    <docs>
      <doc path="bmad-docs/PRD.md" title="Product Requirements Document v3.1.0-Hybrid" section="Functional Requirements">
        <snippet>FR001: MCP Server Setup & Tool/Resource Implementation - Das System implementiert einen Python-basierten MCP Server mit 7 Tools und 5 Resources (memory://l2-insights, memory://working-memory, memory://episode-memory, memory://l0-raw, memory://stale-memory).</snippet>
      </doc>
      <doc path="bmad-docs/PRD.md" title="Product Requirements Document v3.1.0-Hybrid" section="User Journey">
        <snippet>Episode Memory Check (MCP Resource) - Claude Code liest `memory://episode-memory` vor Answer Generation, um vergangene ähnliche Queries + Reflexionen abzurufen ("Lessons Learned").</snippet>
      </doc>
      <doc path="bmad-docs/architecture.md" title="Cognitive Memory System v3.1.0-Hybrid - Architektur" section="Systemarchitektur">
        <snippet>MCP Resources (Read-Only State): 5 MCP Resources (memory://l2-insights, memory://working-memory, memory://episode-memory, memory://l0-raw, memory://stale-memory) ermöglichen Claude Code lesenden Zugriff auf Memory-State.</snippet>
      </doc>
      <doc path="bmad-docs/tech-spec-epic-1.md" title="Epic Technical Specification: MCP Server Foundation & Ground Truth Collection" section="MCP Resources">
        <snippet>MCP Resources (5x Read-Only URIs: memory://l2-insights, memory://working-memory, memory://episode-memory, memory://l0-raw, memory://stale-memory) - Resources sind Read-Only, idempotent, GET-like Operations.</snippet>
      </doc>
      <doc path="bmad-docs/epics.md" title="Epic 1: MCP Server Foundation & Ground Truth Collection" section="Story 1.9">
        <snippet>Story 1.9 implementiert MCP Resources für Read-Only State Exposure, enabling Claude Code to read Memory State BEFORE taking actions, enabling context-aware decision making.</snippet>
      </doc>
    </docs>
    <code>
      <artifact path="mcp_server/__main__.py" kind="main" symbol="main" lines="75-141">
        <reason>Main MCP server entry point with resource registration pattern and stdio transport setup</reason>
      </artifact>
      <artifact path="mcp_server/resources/__init__.py" kind="module" symbol="register_resources" lines="202-284">
        <reason>Existing resource registration framework and stub implementations for all 5 required resources</reason>
      </artifact>
      <artifact path="mcp_server/resources/__init__.py" kind="function" symbol="parse_resource_uri" lines="23-41">
        <reason>URI parsing function that extracts path and query parameters from memory:// URIs</reason>
      </artifact>
      <artifact path="mcp_server/resources/__init__.py" kind="function" symbol="get_single_param" lines="43-57">
        <reason>Helper function to extract single parameter values from query parameters</reason>
      </artifact>
      <artifact path="mcp_server/tools/__init__.py" kind="function" symbol="get_embedding_with_retry" lines="342-368">
        <reason>Reusable OpenAI embeddings function with exponential backoff retry logic - must be imported for resources 1 and 3</reason>
      </artifact>
      <artifact path="mcp_server/tools/__init__.py" kind="function" symbol="semantic_search" lines="98-140">
        <reason>Semantic search implementation using pgvector - can be reused pattern for resources 1 and 3</reason>
      </artifact>
      <artifact path="mcp_server/db/connection.py" kind="module" symbol="get_connection" lines="67-88">
        <reason>Database connection context manager with DictCursor for all resource database operations</reason>
      </artifact>
    </code>
    <dependencies>
      <ecosystem name="python">
        <package name="mcp" version="^1.0.0" purpose="MCP SDK for server implementation" />
        <package name="psycopg2-binary" version="^2.9.0" purpose="PostgreSQL database driver" />
        <package name="pgvector" version="^0.2.0" purpose="PostgreSQL vector extension support" />
        <package name="openai" version="^1.0.0" purpose="OpenAI API client for embeddings" />
        <package name="anthropic" version="^0.25.0" purpose="Anthropic API client for Haiku (future use)" />
        <package name="numpy" version="^1.24.0" purpose="Numerical operations and vector handling" />
        <package name="python-dotenv" version="^1.0.0" purpose="Environment variable management" />
      </ecosystem>
      <ecosystem name="dev">
        <package name="black" version="^23.0.0" purpose="Code formatting" />
        <package name="ruff" version="^0.1.0" purpose="Linting and code quality" />
        <package name="mypy" version="^1.7.0" purpose="Static type checking (--strict mode)" />
        <package name="pytest" version="^7.4.0" purpose="Testing framework" />
        <package name="pytest-cov" version="^4.1.0" purpose="Coverage reporting" />
      </ecosystem>
      <external name="OpenAI API">
        <service name="text-embedding-3-small" purpose="1536-dimensional text embeddings" cost="€0.02 per 1M tokens" />
      </external>
      <external name="PostgreSQL">
        <service name="PostgreSQL 15+" purpose="Database with pgvector extension" deployment="local" />
      </external>
    </dependencies>
  </artifacts>

  <constraints>
      <constraint type="pattern" name="Read-Only Resources">
        <rule>All MCP Resources must be read-only - no INSERT/UPDATE/DELETE operations allowed</rule>
        <rationale>Resources provide state exposure, tools handle state mutations</rationale>
      </constraint>
      <constraint type="pattern" name="Error Handling">
        <rule>400 Bad Request for invalid parameters, empty array [] for no results, 404 only for invalid URIs</rule>
        <rationale>Consistent error handling per AC specification</rationale>
      </constraint>
      <constraint type="pattern" name="Code Reuse">
        <rule>Import and reuse existing get_embedding_with_retry function - DO NOT duplicate</rule>
        <rationale>DRY principle and consistent retry logic</rationale>
      </constraint>
      <constraint type="pattern" name="Database Connection">
        <rule>Use get_connection() context manager for all database operations</rule>
        <rationale>Proper connection pooling and transaction management</rationale>
      </constraint>
      <constraint type="pattern" name="pgvector Registration">
        <rule>Call register_vector(conn) before any pgvector operations</rule>
        <rationale>Required for pgvector type recognition in psycopg2</rationale>
      </constraint>
      <constraint type="quality" name="Type Hints">
        <rule>All functions must have complete type hints for mypy --strict compliance</rule>
        <rationale>Code quality standards from Dev Notes</rationale>
      </constraint>
      <constraint type="performance" name="Query Limits">
        <rule>Resource 4 limit parameter: default 100, max 1000, clamp between values</rule>
        <rationale>Prevent excessive database load</rationatie>
      </constraint>
      <constraint type="security" name="Parameter Validation">
        <rule>Validate all query parameters (UUID format, date ranges, numeric ranges)</rule>
        <rationale>Prevent SQL injection and invalid API calls</rationale>
      </constraint>
    </constraints>
  <interfaces>
      <interface name="MCP Resource Read Interface" kind="MCP Protocol">
        <signature>@server.read_resource() async def read_resource_handler(uri: str) -> dict[str, Any]</signature>
        <path>mcp_server/resources/__init__.py</path>
      </interface>
      <interface name="OpenAI Embeddings API" kind="External API">
        <signature>async def get_embedding_with_retry(client: OpenAI, text: str, max_retries: int = 3) -> list[float]</signature>
        <path>mcp_server/tools/__init__.py</path>
      </interface>
      <interface name="Database Connection Context Manager" kind="Database">
        <signature>@contextmanager def get_connection() -> Iterator[connection]</signature>
        <path>mcp_server/db/connection.py</path>
      </interface>
      <interface name="PostgreSQL pgvector Semantic Search" kind="Database Query">
        <signature>SELECT id, content, embedding <=> %s AS distance FROM table ORDER BY distance LIMIT %s</signature>
        <path>Database schema and query patterns</path>
      </interface>
      <interface name="Resource URI Parsing" kind="Utility Function">
        <signature>def parse_resource_uri(uri: str) -> tuple[str, dict[str, list[str]]]</signature>
        <path>mcp_server/resources/__init__.py</path>
      </interface>
    </interfaces>
  <tests>
    <standards>Integration tests with real PostgreSQL database following existing patterns. Tests use pytest with async support and must cleanup test data in teardown. All tests validate both success scenarios and error handling (400 for invalid params, empty array [] for no results). Code must pass mypy --strict, black formatting, and ruff linting.</standards>
    <locations>tests/test_resources.py (new file for resource-specific tests), tests/test_mcp_server.py (existing end-to-end MCP tests)</locations>
    <ideas>
      <test ac="1" name="l2-insights semantic search">
        <description>Test query embedding generation + pgvector semantic search returning Top-K results with proper score format</description>
        <setup>Insert test L2 insights with embeddings, call memory://l2-insights?query=test&top_k=5</setup>
      </test>
      <test ac="2" name="working-memory sorting">
        <description>Verify working memory items are returned sorted by last_accessed DESC (newest first)</description>
        <setup>Insert multiple working memory items with different timestamps, verify order</setup>
      </test>
      <test ac="3" name="episode-memory similarity filtering">
        <description>Test semantic search with min_similarity threshold and Top-3 limit (FR009)</description>
        <setup>Insert episodes with varying similarities, test with min_similarity=0.70 returns only relevant results</setup>
      </test>
      <test ac="4" name="l0-raw parameter validation">
        <description>Test session_id UUID validation and date_range parsing (YYYY-MM-DD:YYYY-MM-DD format)</description>
        <setup>Test invalid UUID → 400, invalid date format → 400, valid parameters → results</setup>
      </test>
      <test ac="5" name="stale-memory importance filtering">
        <description>Test optional importance_min parameter filtering archived items</description>
        <setup>Insert stale memory items with various importance levels, verify filtering works</setup>
      </test>
      <test ac="all" name="read-only verification">
        <description>Critical test: Verify resources do NOT mutate database state (count rows before/after)</description>
        <setup>Count all table rows, call each resource, count again, assert no changes</setup>
      </test>
      <test ac="all" name="error handling consistency">
        <description>Test error responses: invalid parameters → 400, no results → empty array [], invalid URI → 404</description>
        <setup>Test edge cases: empty query, invalid dates, negative limits, malformed URIs</setup>
      </test>
      <test ac="all" name="end-to-end MCP protocol">
        <description>Test all 5 resources via MCP protocol using read_resource() calls</description>
        <setup>Use MCP client to read all resources, verify response format matches specification</setup>
      </test>
    </ideas>
  </tests>
</story-context>
